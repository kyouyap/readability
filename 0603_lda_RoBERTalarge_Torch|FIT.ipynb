{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "0603 lda RoBERTalarge Torch|FIT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1viI5wNcdg3yUPuxz92MJq1mmSVGHyZFR",
      "authorship_tag": "ABX9TyOHYC+Kvr3grjqsu8/y14go",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62bfed4672284fe090b7cdd0c161abf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6efd5a540ab8440382a95e958ef6a1b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_281ecd9bf1734a46bdbd93cdb1d04ae7",
              "IPY_MODEL_661e0899512f46c68d2745b197e52086"
            ]
          }
        },
        "6efd5a540ab8440382a95e958ef6a1b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "281ecd9bf1734a46bdbd93cdb1d04ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ef63c46b0c7499d802b3c5435493e91",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b16097df991c4b54863df9dbbee7861f"
          }
        },
        "661e0899512f46c68d2745b197e52086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3dfd55ee5f644986b51cbd0f7a41cf34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 792B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b7755a978844a71aa037647464ad25a"
          }
        },
        "1ef63c46b0c7499d802b3c5435493e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b16097df991c4b54863df9dbbee7861f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dfd55ee5f644986b51cbd0f7a41cf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b7755a978844a71aa037647464ad25a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5fdce6be7e24e869b7642bc4212251a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd0dad0c0d29441b8dc605fac3354bda",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8f4700cef5e4edb8ac991708447179c",
              "IPY_MODEL_0d7967e117d146b183a6f06b271d4aee"
            ]
          }
        },
        "bd0dad0c0d29441b8dc605fac3354bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8f4700cef5e4edb8ac991708447179c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62c8e43b425b4a869386f66efda7b677",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b59097f42052479b8bc9c2ae98b1e44a"
          }
        },
        "0d7967e117d146b183a6f06b271d4aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3db62caf24df4549be9ffe4a4c93444d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 588kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffd9c9bff6bc43d68d9eb11b8df36f43"
          }
        },
        "62c8e43b425b4a869386f66efda7b677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b59097f42052479b8bc9c2ae98b1e44a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3db62caf24df4549be9ffe4a4c93444d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffd9c9bff6bc43d68d9eb11b8df36f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13c93fe0d10b498b82c89c91a143aa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf4856b98d3c45d6b76d996831f1aade",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d72d68ca8a84d9ba76d55c1f4bf4934",
              "IPY_MODEL_f0c510fc89bb47b3819e882eeb688f50"
            ]
          }
        },
        "cf4856b98d3c45d6b76d996831f1aade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d72d68ca8a84d9ba76d55c1f4bf4934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70a9025676d34fefb7f5f8c3f69d38bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f095fac99a7f4771a530b5937274154f"
          }
        },
        "f0c510fc89bb47b3819e882eeb688f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_036ae9e86a0d48abb9d7ba0641fb914d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 615kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc28807b59774ed48d497583b1039df9"
          }
        },
        "70a9025676d34fefb7f5f8c3f69d38bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f095fac99a7f4771a530b5937274154f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "036ae9e86a0d48abb9d7ba0641fb914d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc28807b59774ed48d497583b1039df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1688158579e64f7d8c1af9ff49cd8443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e493ed437b54382bacb32b233919dcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d75d772e9b414a94a60ff9236955921b",
              "IPY_MODEL_54b3ea3bb11845b8923f8ad5c64d16fd"
            ]
          }
        },
        "9e493ed437b54382bacb32b233919dcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d75d772e9b414a94a60ff9236955921b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee77670cf29e4d4baf961d8b1ea9d531",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b6f5837ad5d460bacae950c8bc284fe"
          }
        },
        "54b3ea3bb11845b8923f8ad5c64d16fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a8cf64253324e6295cff4430c08954a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:02&lt;00:00, 503kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0abbdde4b240beb20ccfb6a30a147a"
          }
        },
        "ee77670cf29e4d4baf961d8b1ea9d531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b6f5837ad5d460bacae950c8bc284fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a8cf64253324e6295cff4430c08954a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0abbdde4b240beb20ccfb6a30a147a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyouyap/readability/blob/master/0603_lda_RoBERTalarge_Torch%7CFIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJoay0U4-s7r",
        "outputId": "9a6c6147-1e92-478f-ad40-d55e7e37e562"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "if 'KAGGLE_URL_BASE' in set(os.environ.keys()):\n",
        "    train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
        "    test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
        "    print(\"train shape\",train.shape)\n",
        "# colaboratory環境ならTrue\n",
        "elif 'COLAB_GPU' in set(os.environ.keys()):\n",
        "    train = pd.read_csv(\"/content/drive/MyDrive/kaggle/readability/train.csv\")\n",
        "    test = pd.read_csv(\"/content/drive/MyDrive/kaggle/readability/test.csv\")\n",
        "    print(\"train shape\",train.shape)\n",
        "df=pd.concat([train,test])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape (2834, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWLBC21klVwI",
        "outputId": "f26ca953-b88b-41dc-bf68-8af8392d03b4"
      },
      "source": [
        "for i in train.sort_values(\"target\").head(5).excerpt:\n",
        "    print(i)\n",
        "    print()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The commutator is peculiar, consisting of only three segments of a copper ring, while in the simplest of other continuous current generators several times that number exist, and frequently 120! segments are to be found. These three segments are made so as to be removable in a moment for cleaning or replacement. They are mounted upon a metal support, and are surrounded on all sides by a free air space, and cannot, therefore, lose their insulated condition. This feature of air insulation is peculiar to this system, and is very important as a factor in the durability of the commutator. Besides this, the commutator is sustained by supports carried in flanges upon the shaft, which flanges, as an additional safeguard, are coated all over with hard rubber, one of the finest known insulators. It may be stated, without fear of contradiction, that no other commutator made is so thoroughly insulated and protected. The three commutator segments virtually constitute a single copper ring, mounted in free air, and cut into three equal pieces by slots across its face.\n",
            "\n",
            "The Dunwich horror itself came between Lammas and the equinox in 1928, and Dr. Armitage was among those who witnessed its monstrous prologue. He had heard, meanwhile, of Whateley's grotesque trip to Cambridge, and of his frantic efforts to borrow or copy from the Necronomicon at the Widener Library. Those efforts had been in vain, since Armitage had issued warnings of the keenest intensity to all librarians having charge of the dreaded volume. Wilbur had been shockingly nervous at Cambridge; anxious for the book, yet almost equally anxious to get home again, as if he feared the results of being away long.\n",
            "Early in August the half-expected outcome developed, and in the small hours of the third Dr. Armitage was awakened suddenly by the wild, fierce cries of the savage watchdog on the college campus. Deep and terrible, the snarling, half-mad growls and barks continued; always in mounting volume, but with hideously significant pauses. Then there rang out a scream from a wholly different throat—such a scream as roused half the sleepers of Arkham and haunted their dreams ever afterward—such a scream as could come from not being born of earth, or wholly of earth.\n",
            "\n",
            "The iron cylinder weighs 23 kilogrammes; but, when the current has an intensity of 43 amperes and traverses 15 sections, the stress developed may reach 70 kilogrammes; that is to say, three times the weight of the hammer. So this latter obeys with absolute docility the motions of the operator's hands, as those who were present at the lecture were enabled to see. I will incidentally add that this power hammer was placed on a circuit derived from one that served likewise to supply three Hefner-Alteneck machines (Siemens D5 model) and a Gramme machine (Breguet model P.L.). Each of these machines was making 1,500 revolutions per minute and developing 25 kilogrammeters per second, measured by means of a Carpentier brake. All these apparatuses were operating with absolute independence, and had for generators the double excitation machine that figured at the Exhibition of Electricity. In an experiment made since then, I have succeeded in developing in each of these four machines 50 kilogrammeters per second, whatever was the number of those that were running; and I found it possible to add the hammer on a derived circuit without notably affecting the operation of the receivers.\n",
            "\n",
            "As to surface-slope its measurement—from nearly 600 trials—was found to be such a delicate operation that the result would be of doubtful utility. This would affect the application of all formulas into which it entered. The water surface was ascertained, on the average of its oscillations, to be sensibly level across, not convex, as supposed by some writers. There were 565 sets of vertical velocity measurements combined into forty-six series. The forty-six average curves were all very flat and convex downstream—except near an irregular bank—and were approximately parabolas with horizontal axes; the data determined the parameters only very roughly; the maximum velocity line was usually below the service, and sank in a rectangular channel, from the center outward down to about mid-depth near the banks. Its depression seemed not to depend on the depth, slope, velocity, or wind; probably the air itself, being a continuous source of surface retardation, would permanently depress the maximum velocity, while wind failed to effect this, owing to its short duration. On any vertical the mid-depth velocity was greater than the mean, and the bed velocity was the least.\n",
            "\n",
            "The tree is dioecious, bearing male catkins on one plant, female on another. All the female trees in Europe are believed to have originated from a tree near Geneva, of which Auguste Pyramus de Candolle secured grafts, and distributed them throughout the Continent. Nevertheless, the female tree is rarely met with, as compared with the male; but it is quite possible that a tree which generally produces male flowers only may sometimes bear female flowers only. We have no certain evidence of this in the case of the Gingkgo, but it is a common enough occurrence in other dioecious plants, and the occurrence of a fruiting specimen near Philadelphia, as recently recorded by Mr. Meehan, may possibly be attributed to this cause.\n",
            "The tree of which we give a figure is growing at Broadlands, Hants, and is about 40 feet in height, with a trunk that measures 7 feet in girth at 3 feet from the ground, with a spread of branches measuring 45 feet. These dimensions have been considerably exceeded in other cases. In 1837 a tree at Purser's Cross measured 60 feet and more in height.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGjk0-6_Bxom"
      },
      "source": [
        "from sklearn import model_selection\n",
        "def create_folds(data, num_splits):\n",
        "    data[\"kfold\"] = -1\n",
        "    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2021)\n",
        "    for f, (t_, v_) in enumerate(kf.split(X=data)):\n",
        "        data.loc[v_, 'kfold'] = f\n",
        "    return data\n",
        "train = create_folds(train, num_splits=5)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4VlxGVdadh2",
        "outputId": "86f9865b-421f-41a3-c643-fe482a4697d8"
      },
      "source": [
        "!pip install -q lda\n",
        "import lda\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import joblib\n",
        "import time\n",
        "\n",
        "bow_model = CountVectorizer(stop_words='english')\n",
        "bow = bow_model.fit_transform(df.excerpt)\n",
        "\n",
        "n = 20\n",
        "n_iter = 2000\n",
        "start = time.time()\n",
        "lda_model = lda.lda.LDA(n_topics=n, n_iter=n_iter, random_state=0, refresh=100)\n",
        "lda_model.fit(bow)\n",
        "# 初回実行時のみ保存\n",
        "joblib.dump(lda_model, 'lda_model_{}_{}iter.pkl'.format(n, n_iter))\n",
        "end = time.time()\n",
        "print(\"topic_N =\", str(n), \"train time\", end - start)\n",
        "\n",
        "joblib.dump(lda_model, 'lda_model_{}_{}iter.pkl'.format(n, n_iter))\n",
        "lda_model = joblib.load('lda_model_20_2000iter.pkl')\n",
        "\n",
        "bow = bow_model.transform(df.excerpt)\n",
        "theta_docs_20 = lda_model.transform(bow)\n",
        "\n",
        "train_theta = theta_docs_20[:len(train)]\n",
        "test_theta = theta_docs_20[len(train):]\n",
        "\n",
        "train_topic = train_theta.argmax(axis=1)\n",
        "test_topic = test_theta.argmax(axis=1)\n",
        "\n",
        "train['topic_id'] = train_topic\n",
        "test['topic_id'] = test_topic\n",
        "\n",
        "train_theta_df = pd.DataFrame(train_theta)\n",
        "train_theta_df.columns = [f'topic{i}' for i in range(train_theta.shape[1])]\n",
        "test_theta_df = pd.DataFrame(test_theta)\n",
        "test_theta_df.columns = [f'topic{i}' for i in range(test_theta.shape[1])]\n",
        "\n",
        "train = pd.concat([train, train_theta_df], axis=1)\n",
        "test = pd.concat([test, test_theta_df], axis=1)\n",
        "\n",
        "train.excerpt = '[' + train.topic_id.map(str) + '] </s> '+train.excerpt\n",
        "test.excerpt =  '[' + test.topic_id.map(str) + '] </s> '+test.excerpt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 358kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:lda:n_documents: 2841\n",
            "INFO:lda:vocab_size: 26560\n",
            "INFO:lda:n_words: 222894\n",
            "INFO:lda:n_topics: 20\n",
            "INFO:lda:n_iter: 2000\n",
            "INFO:lda:<0> log likelihood: -3048240\n",
            "INFO:lda:<100> log likelihood: -2071927\n",
            "INFO:lda:<200> log likelihood: -2056920\n",
            "INFO:lda:<300> log likelihood: -2050077\n",
            "INFO:lda:<400> log likelihood: -2047607\n",
            "INFO:lda:<500> log likelihood: -2045323\n",
            "INFO:lda:<600> log likelihood: -2043343\n",
            "INFO:lda:<700> log likelihood: -2043339\n",
            "INFO:lda:<800> log likelihood: -2041947\n",
            "INFO:lda:<900> log likelihood: -2041675\n",
            "INFO:lda:<1000> log likelihood: -2042541\n",
            "INFO:lda:<1100> log likelihood: -2042228\n",
            "INFO:lda:<1200> log likelihood: -2041705\n",
            "INFO:lda:<1300> log likelihood: -2040984\n",
            "INFO:lda:<1400> log likelihood: -2041800\n",
            "INFO:lda:<1500> log likelihood: -2041274\n",
            "INFO:lda:<1600> log likelihood: -2041307\n",
            "INFO:lda:<1700> log likelihood: -2040785\n",
            "INFO:lda:<1800> log likelihood: -2041372\n",
            "INFO:lda:<1900> log likelihood: -2041318\n",
            "INFO:lda:<1999> log likelihood: -2040047\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "topic_N = 20 train time 97.02572202682495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wilSYz37B1LR"
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPnDb-W1B2fu",
        "outputId": "e11c2303-022d-49e0-9e02-5b728baac8a0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import (\n",
        "    Dataset, DataLoader, \n",
        "    SequentialSampler, RandomSampler\n",
        ")\n",
        "!pip install transformers\n",
        "from transformers import AutoConfig\n",
        "from transformers import (\n",
        "    get_cosine_schedule_with_warmup, \n",
        "    get_cosine_with_hard_restarts_schedule_with_warmup\n",
        ")\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm, trange\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, huggingface-hub, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUZan8AdCInc"
      },
      "source": [
        "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
        "    data = data.replace('\\n', '')\n",
        "    tok = tokenizer.encode_plus(\n",
        "        data, \n",
        "        max_length=max_len, \n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True\n",
        "    )\n",
        "    curr_sent = {}\n",
        "    padding_length = max_len - len(tok['input_ids'])\n",
        "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
        "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
        "        ([0] * padding_length)\n",
        "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
        "        ([0] * padding_length)\n",
        "    return curr_sent"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niK6D18uCSdn"
      },
      "source": [
        "class DatasetRetriever(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
        "        self.data = data\n",
        "        if 'excerpt' in self.data.columns:\n",
        "            self.excerpts = self.data.excerpt.values.tolist()\n",
        "        else:\n",
        "            self.excerpts = self.data.text.values.tolist()\n",
        "        self.targets = self.data.target.values.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.is_test = is_test\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        excerpt, label = self.excerpts[item], self.targets[item]\n",
        "        features = convert_examples_to_features(\n",
        "            excerpt, self.tokenizer, \n",
        "            self.max_len, self.is_test\n",
        "        )\n",
        "        return {\n",
        "            'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
        "            'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
        "            'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
        "            'label':torch.tensor(label, dtype=torch.double),\n",
        "        }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH2K91nfCWLB"
      },
      "source": [
        "class CommonLitModel(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_name, \n",
        "        config,  \n",
        "        multisample_dropout=False,\n",
        "        output_hidden_states=False\n",
        "    ):\n",
        "        super(CommonLitModel, self).__init__()\n",
        "        self.config = config\n",
        "        self.roberta = AutoModel.from_pretrained(\n",
        "            model_name, \n",
        "            output_hidden_states=output_hidden_states\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
        "        if multisample_dropout:\n",
        "            self.dropouts = nn.ModuleList([\n",
        "                nn.Dropout(0.5) for _ in range(5)\n",
        "            ])\n",
        "        else:\n",
        "            self.dropouts = nn.ModuleList([nn.Dropout(0.1)])\n",
        "        #self.regressor = nn.Linear(config.hidden_size*2, 1)\n",
        "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
        "        self._init_weights(self.layer_norm)\n",
        "        self._init_weights(self.regressor)\n",
        " \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        " \n",
        "    def forward(\n",
        "        self, \n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        labels=None\n",
        "    ):\n",
        "        outputs = self.roberta(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "        sequence_output = outputs[1]\n",
        "        sequence_output = self.layer_norm(sequence_output)\n",
        " \n",
        "        # max-avg head\n",
        "        # average_pool = torch.mean(sequence_output, 1)\n",
        "        # max_pool, _ = torch.max(sequence_output, 1)\n",
        "        # concat_sequence_output = torch.cat((average_pool, max_pool), 1)\n",
        " \n",
        "        # multi-sample dropout\n",
        "        for i, dropout in enumerate(self.dropouts):\n",
        "            if i == 0:\n",
        "                logits = self.regressor(dropout(sequence_output))\n",
        "            else:\n",
        "                logits += self.regressor(dropout(sequence_output))\n",
        "        \n",
        "        logits /= len(self.dropouts)\n",
        " \n",
        "        # calculate loss\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # regression task\n",
        "            loss_fn = torch.nn.MSELoss()\n",
        "            logits = logits.view(-1).to(labels.dtype)\n",
        "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
        "        \n",
        "        output = (logits,) + outputs[1:]\n",
        "        return ((loss,) + output) if loss is not None else output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta2DtpTNChIG"
      },
      "source": [
        "\n",
        "class Lamb(Optimizer):\n",
        "    # Reference code: https://github.com/cybertronai/pytorch-lamb\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr: float = 1e-3,\n",
        "        betas = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0,\n",
        "        clamp_value: float = 10,\n",
        "        adam: bool = False,\n",
        "        debias: bool = False,\n",
        "    ):\n",
        "        if lr <= 0.0:\n",
        "            raise ValueError('Invalid learning rate: {}'.format(lr))\n",
        "        if eps < 0.0:\n",
        "            raise ValueError('Invalid epsilon value: {}'.format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\n",
        "                'Invalid beta parameter at index 0: {}'.format(betas[0])\n",
        "            )\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\n",
        "                'Invalid beta parameter at index 1: {}'.format(betas[1])\n",
        "            )\n",
        "        if weight_decay < 0:\n",
        "            raise ValueError(\n",
        "                'Invalid weight_decay value: {}'.format(weight_decay)\n",
        "            )\n",
        "        if clamp_value < 0.0:\n",
        "            raise ValueError('Invalid clamp value: {}'.format(clamp_value))\n",
        "\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.clamp_value = clamp_value\n",
        "        self.adam = adam\n",
        "        self.debias = debias\n",
        "\n",
        "        super(Lamb, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure = None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    msg = (\n",
        "                        'Lamb does not support sparse gradients, '\n",
        "                        'please consider SparseAdam instead'\n",
        "                    )\n",
        "                    raise RuntimeError(msg)\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(\n",
        "                        p, memory_format=torch.preserve_format\n",
        "                    )\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(\n",
        "                        p, memory_format=torch.preserve_format\n",
        "                    )\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
        "\n",
        "                # Paper v3 does not use debiasing.\n",
        "                if self.debias:\n",
        "                    bias_correction = math.sqrt(1 - beta2 ** state['step'])\n",
        "                    bias_correction /= 1 - beta1 ** state['step']\n",
        "                else:\n",
        "                    bias_correction = 1\n",
        "\n",
        "                # Apply bias to lr to avoid broadcast.\n",
        "                step_size = group['lr'] * bias_correction\n",
        "\n",
        "                weight_norm = torch.norm(p.data).clamp(0, self.clamp_value)\n",
        "\n",
        "                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n",
        "                if group['weight_decay'] != 0:\n",
        "                    adam_step.add_(p.data, alpha=group['weight_decay'])\n",
        "\n",
        "                adam_norm = torch.norm(adam_step)\n",
        "                if weight_norm == 0 or adam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / adam_norm\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = adam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "                if self.adam:\n",
        "                    trust_ratio = 1\n",
        "\n",
        "                p.data.add_(adam_step, alpha=-step_size * trust_ratio)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eravelFCqWX"
      },
      "source": [
        "def get_optimizer_params(model):\n",
        "    # 微分学習率とウェイトディケイ\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    learning_rate = 5e-5\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n",
        "    group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n",
        "    group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n",
        "    group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n",
        "    optimizer_parameters = [\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay_rate': 0.01, 'lr': learning_rate/2.6},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay_rate': 0.01, 'lr': learning_rate},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay_rate': 0.01, 'lr': learning_rate*2.6},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay_rate': 0.0},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay_rate': 0.0, 'lr': learning_rate/2.6},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay_rate': 0.0, 'lr': learning_rate},\n",
        "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay_rate': 0.0, 'lr': learning_rate*2.6},\n",
        "        {'params': [p for n, p in model.named_parameters() if \"roberta\" not in n], 'lr':1e-3, \"momentum\" : 0.99},\n",
        "    ]\n",
        "    return optimizer_parameters"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzSCMdloCtg2"
      },
      "source": [
        "\n",
        "def make_model(model_name='../input/robertaitpt/', num_labels=1):\n",
        "    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "    config = AutoConfig.from_pretrained(model_name)\n",
        "    config.update({'num_labels':num_labels})\n",
        "    model = CommonLitModel(model_name, config=config)\n",
        "    return model, tokenizer\n",
        "\n",
        "def make_optimizer(model, optimizer_name=\"AdamW\"):\n",
        "    optimizer_grouped_parameters = get_optimizer_params(model)\n",
        "    kwargs = {\n",
        "            'lr':3e-5,\n",
        "            'weight_decay':0\n",
        "    }\n",
        "    if optimizer_name == \"LAMB\":\n",
        "        optimizer = Lamb(optimizer_grouped_parameters, **kwargs)\n",
        "        return optimizer\n",
        "    elif optimizer_name == \"Adam\":\n",
        "        from torch.optim import Adam\n",
        "        optimizer = Adam(optimizer_grouped_parameters, **kwargs)\n",
        "        return optimizer\n",
        "    elif optimizer_name == \"AdamW\":\n",
        "        from torch.optim import AdamW\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, **kwargs)\n",
        "        return optimizer\n",
        "    else:\n",
        "        raise Exception('Unknown optimizer: {}'.format(optimizer_name))\n",
        "\n",
        "def make_scheduler(optimizer, decay_name='cosine_warmup', t_max=10):\n",
        "    if decay_name == 'step':\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer,\n",
        "            milestones=[30, 60, 90],\n",
        "            gamma=0.1\n",
        "        )\n",
        "    elif decay_name == 'cosine':\n",
        "        scheduler = lrs.CosineAnnealingLR(\n",
        "            optimizer,\n",
        "            T_max=t_max\n",
        "        )\n",
        "    elif decay_name == \"cosine_warmup\":\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=t_max\n",
        "        )\n",
        "    else:\n",
        "        raise Exception('Unknown lr scheduler: {}'.format(decay_type))    \n",
        "    return scheduler    \n",
        "\n",
        "def make_loader(\n",
        "    data, \n",
        "    tokenizer, \n",
        "    max_len,\n",
        "    batch_size,\n",
        "    fold=0\n",
        "):\n",
        "    train_set, valid_set = data[data['kfold']!=fold], data[data['kfold']==fold]\n",
        "    train_dataset = DatasetRetriever(train_set, tokenizer, max_len)\n",
        "    valid_dataset = DatasetRetriever(valid_set, tokenizer, max_len)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=batch_size, \n",
        "        sampler=train_sampler, \n",
        "        pin_memory=True, \n",
        "        drop_last=False, \n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    valid_sampler = SequentialSampler(valid_dataset)\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset, \n",
        "        batch_size=batch_size // 2, \n",
        "        sampler=valid_sampler, \n",
        "        pin_memory=True, \n",
        "        drop_last=False, \n",
        "        num_workers=4\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gj_e7waCxvH"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        self.max = 0\n",
        "        self.min = 1e5\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        if val > self.max:\n",
        "            self.max = val\n",
        "        if val < self.min:\n",
        "            self.min = val"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCd8UAExC0SK"
      },
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, scheduler, scalar=None, log_interval=1, evaluate_interval=1):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.scalar = scalar\n",
        "        self.log_interval = log_interval\n",
        "        self.evaluate_interval = evaluate_interval\n",
        "        self.evaluator = Evaluator(self.model, self.scalar)\n",
        "\n",
        "    def train(self, train_loader, valid_loader, epoch, \n",
        "              result_dict, tokenizer, fold):\n",
        "        total_loss = 0\n",
        "        count = 0\n",
        "\n",
        "        losses = AverageMeter()\n",
        "\n",
        "        self.model.train()\n",
        "        \n",
        "        for batch_idx, batch_data in enumerate(train_loader):\n",
        "            input_ids, attention_mask, token_type_ids, labels = batch_data['input_ids'], \\\n",
        "                batch_data['attention_mask'], batch_data['token_type_ids'], batch_data['label']\n",
        "            input_ids, attention_mask, token_type_ids, labels = \\\n",
        "                input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n",
        "\n",
        "            \n",
        "            if self.scalar is not None:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = self.model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        labels=labels\n",
        "                    )\n",
        "            else:\n",
        "                outputs = self.model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=token_type_ids,\n",
        "                    labels=labels\n",
        "                )\n",
        "            \n",
        "#             torch.nn.utils.clip_grad_norm_(\n",
        "#                 parameters=self.model.parameters(), \n",
        "#                 max_norm=1.0\n",
        "#             )\n",
        "\n",
        "            loss, logits = outputs[:2]\n",
        "            total_loss += loss.tolist()\n",
        "            count += labels.size(0)\n",
        "\n",
        "            logits = logits.cpu().detach().numpy()\n",
        "            losses.update(loss.item(), input_ids.size(0))\n",
        "            \n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            if self.scalar is not None:\n",
        "                self.scalar.scale(loss).backward()\n",
        "                self.scalar.step(self.optimizer)\n",
        "                self.scalar.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "            if batch_idx % self.log_interval == 0:\n",
        "                _s = str(len(str(len(train_loader.sampler))))\n",
        "                ret = [\n",
        "                    ('epoch: {:0>3} [{: >' + _s + '}/{} ({: >3.0f}%)]').format(epoch, count, len(train_loader.sampler), 100 * count / len(train_loader.sampler)),\n",
        "                    'train_loss: {: >4.5f}'.format(total_loss / count),\n",
        "                ]\n",
        "                print(', '.join(ret))\n",
        "            \n",
        "            if batch_idx % self.evaluate_interval == 0:\n",
        "                result_dict = self.evaluator.evaluate(\n",
        "                    valid_loader, \n",
        "                    epoch, \n",
        "                    result_dict, \n",
        "                    tokenizer\n",
        "                )\n",
        "                if result_dict['val_loss'][-1] < result_dict['best_val_loss']:\n",
        "                    print(\"{} epoch, best epoch was updated! valid_loss: {: >4.5f}\".format(epoch, result_dict['val_loss'][-1]))\n",
        "                    result_dict[\"best_val_loss\"] = result_dict['val_loss'][-1]\n",
        "                    torch.save(self.model.state_dict(), f\"model{fold}.bin\")\n",
        "\n",
        "        self.scheduler.step()\n",
        "        result_dict['train_loss'].append(losses.avg)\n",
        "        return result_dict"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzNyJYguC4o_"
      },
      "source": [
        "class Evaluator:\n",
        "    def __init__(self, model, scalar=None):\n",
        "        self.model = model\n",
        "        self.scalar = scalar\n",
        "    \n",
        "    def worst_result(self):\n",
        "        ret = {\n",
        "            'loss':float('inf'),\n",
        "            'accuracy':0.0\n",
        "        }\n",
        "        return ret\n",
        "\n",
        "    def result_to_str(self, result):\n",
        "        ret = [\n",
        "            'epoch: {epoch:0>3}',\n",
        "            'loss: {loss: >4.2e}'\n",
        "        ]\n",
        "        for metric in self.evaluation_metrics:\n",
        "            ret.append('{}: {}'.format(metric.name, metric.fmtstr))\n",
        "        return ', '.join(ret).format(**result)\n",
        "\n",
        "    def save(self, result):\n",
        "        with open('result_dict.json', 'w') as f:\n",
        "            f.write(json.dumps(result, sort_keys=True, indent=4, ensure_ascii=False))\n",
        "    \n",
        "    def load(self):\n",
        "        result = self.worst_result\n",
        "        if os.path.exists('result_dict.json'):\n",
        "            with open('result_dict.json', 'r') as f:\n",
        "                try:\n",
        "                    result = json.loads(f.read())\n",
        "                except:\n",
        "                    pass\n",
        "        return result\n",
        "\n",
        "    def evaluate(self, data_loader, epoch, result_dict, tokenizer):\n",
        "        losses = AverageMeter()\n",
        "\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch_data in enumerate(data_loader):\n",
        "                input_ids, attention_mask, token_type_ids, labels = batch_data['input_ids'], \\\n",
        "                    batch_data['attention_mask'], batch_data['token_type_ids'], batch_data['label']\n",
        "                input_ids, attention_mask, token_type_ids, labels = input_ids.cuda(), \\\n",
        "                    attention_mask.cuda(), token_type_ids.cuda(), labels.cuda()\n",
        "                \n",
        "                if self.scalar is not None:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = self.model(\n",
        "                            input_ids=input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            labels=labels\n",
        "                        )\n",
        "                else:\n",
        "                    outputs = self.model(\n",
        "                        input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        labels=labels\n",
        "                    )\n",
        "                \n",
        "                loss, logits = outputs[:2]\n",
        "                losses.update(loss.item(), input_ids.size(0))\n",
        "\n",
        "        print('----Validation Results Summary----')\n",
        "        print('Epoch: [{}] train_loss: {: >4.5f}'.format(epoch, losses.avg))\n",
        "\n",
        "        result_dict['val_loss'].append(losses.avg)        \n",
        "        return result_dict"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQzWqXovC8ap"
      },
      "source": [
        "def config(fold=0):\n",
        "    torch.manual_seed(2021)\n",
        "    torch.cuda.manual_seed(2021)\n",
        "    torch.cuda.manual_seed_all(2021)\n",
        "    epochs = 8\n",
        "    max_len = 250\n",
        "    batch_size = 12\n",
        "\n",
        "    model, tokenizer = make_model(model_name='/content/drive/MyDrive/kaggle/readability/robertalarge-e1', num_labels=1)\n",
        "    optimizer = make_optimizer(model, \"AdamW\")\n",
        "    scheduler = make_scheduler(optimizer, t_max=epochs)\n",
        "    train_loader, valid_loader = make_loader(\n",
        "        train, tokenizer, max_len=max_len,\n",
        "        batch_size=batch_size, fold=fold\n",
        "    )\n",
        "\n",
        "    if torch.cuda.device_count() >= 1:\n",
        "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
        "            torch.cuda.device_count(), \n",
        "            torch.cuda.get_device_name(0))\n",
        "        )\n",
        "        model = model.cuda() \n",
        "    else:\n",
        "        raise ValueError('CPU training is not supported')\n",
        "\n",
        "    # scaler = torch.cuda.amp.GradScaler()\n",
        "    scaler = None\n",
        "\n",
        "    result_dict = {\n",
        "        'epoch':[], \n",
        "        'train_loss': [], \n",
        "        'val_loss' : [], \n",
        "        'test_loss': [],\n",
        "        'best_val_loss': np.inf\n",
        "    }\n",
        "    return (\n",
        "        model, tokenizer, \n",
        "        optimizer, scheduler, \n",
        "        scaler, train_loader, \n",
        "        valid_loader, result_dict, \n",
        "        epochs\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrUWqMfdC_BH"
      },
      "source": [
        "def run(fold=0):\n",
        "    model, tokenizer, optimizer, scheduler, scaler, \\\n",
        "        train_loader, valid_loader, result_dict, epochs = config(fold)\n",
        "    import time\n",
        "    trainer = Trainer(model, optimizer, scheduler, scaler, log_interval=2, evaluate_interval=2)\n",
        "    train_time_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        result_dict['epoch'] = epoch\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        tic1 = time.time()\n",
        "\n",
        "        result_dict = trainer.train(train_loader, valid_loader, epoch, \n",
        "                                    result_dict, tokenizer, fold)\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        tic2 = time.time() \n",
        "        train_time_list.append(tic2 - tic1)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    del model, tokenizer, optimizer, scheduler, \\\n",
        "        scaler, train_loader, valid_loader,\n",
        "    gc.collect()\n",
        "    return "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "62bfed4672284fe090b7cdd0c161abf9",
            "6efd5a540ab8440382a95e958ef6a1b6",
            "281ecd9bf1734a46bdbd93cdb1d04ae7",
            "661e0899512f46c68d2745b197e52086",
            "1ef63c46b0c7499d802b3c5435493e91",
            "b16097df991c4b54863df9dbbee7861f",
            "3dfd55ee5f644986b51cbd0f7a41cf34",
            "4b7755a978844a71aa037647464ad25a",
            "a5fdce6be7e24e869b7642bc4212251a",
            "bd0dad0c0d29441b8dc605fac3354bda",
            "b8f4700cef5e4edb8ac991708447179c",
            "0d7967e117d146b183a6f06b271d4aee",
            "62c8e43b425b4a869386f66efda7b677",
            "b59097f42052479b8bc9c2ae98b1e44a",
            "3db62caf24df4549be9ffe4a4c93444d",
            "ffd9c9bff6bc43d68d9eb11b8df36f43",
            "13c93fe0d10b498b82c89c91a143aa80",
            "cf4856b98d3c45d6b76d996831f1aade",
            "8d72d68ca8a84d9ba76d55c1f4bf4934",
            "f0c510fc89bb47b3819e882eeb688f50",
            "70a9025676d34fefb7f5f8c3f69d38bc",
            "f095fac99a7f4771a530b5937274154f",
            "036ae9e86a0d48abb9d7ba0641fb914d",
            "fc28807b59774ed48d497583b1039df9",
            "1688158579e64f7d8c1af9ff49cd8443",
            "9e493ed437b54382bacb32b233919dcb",
            "d75d772e9b414a94a60ff9236955921b",
            "54b3ea3bb11845b8923f8ad5c64d16fd",
            "ee77670cf29e4d4baf961d8b1ea9d531",
            "5b6f5837ad5d460bacae950c8bc284fe",
            "0a8cf64253324e6295cff4430c08954a",
            "3d0abbdde4b240beb20ccfb6a30a147a"
          ]
        },
        "id": "8MD9mL7KDAju",
        "outputId": "2bcf4310-4bc7-442d-fcb3-8740d66119c0"
      },
      "source": [
        "for fold in range(5):\n",
        "    print('----')\n",
        "    print(f'FOLD: {fold}')\n",
        "    run(fold)\n",
        "    print('----')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "FOLD: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 acquired on /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62bfed4672284fe090b7cdd0c161abf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 released on /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 acquired on /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5fdce6be7e24e869b7642bc4212251a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 released on /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 acquired on /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13c93fe0d10b498b82c89c91a143aa80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790481541008 released on /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790371299024 acquired on /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1688158579e64f7d8c1af9ff49cd8443",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 139790371299024 released on /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/kaggle/readability/robertalarge-e1 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/kaggle/readability/robertalarge-e1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "epoch: 000 [  12/2267 (  1%)], train_loss: 0.16452\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.42991\n",
            "0 epoch, best epoch was updated! valid_loss: 1.42991\n",
            "epoch: 000 [  36/2267 (  2%)], train_loss: 0.12753\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.99169\n",
            "0 epoch, best epoch was updated! valid_loss: 0.99169\n",
            "epoch: 000 [  60/2267 (  3%)], train_loss: 0.11068\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.95565\n",
            "0 epoch, best epoch was updated! valid_loss: 0.95565\n",
            "epoch: 000 [  84/2267 (  4%)], train_loss: 0.10475\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.92002\n",
            "0 epoch, best epoch was updated! valid_loss: 0.92002\n",
            "epoch: 000 [ 108/2267 (  5%)], train_loss: 0.09647\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.85364\n",
            "0 epoch, best epoch was updated! valid_loss: 0.85364\n",
            "epoch: 000 [ 132/2267 (  6%)], train_loss: 0.09099\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.90079\n",
            "epoch: 000 [ 156/2267 (  7%)], train_loss: 0.08798\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.83676\n",
            "0 epoch, best epoch was updated! valid_loss: 0.83676\n",
            "epoch: 000 [ 180/2267 (  8%)], train_loss: 0.08656\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.84343\n",
            "epoch: 000 [ 204/2267 (  9%)], train_loss: 0.08326\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73820\n",
            "0 epoch, best epoch was updated! valid_loss: 0.73820\n",
            "epoch: 000 [ 228/2267 ( 10%)], train_loss: 0.08202\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69219\n",
            "0 epoch, best epoch was updated! valid_loss: 0.69219\n",
            "epoch: 000 [ 252/2267 ( 11%)], train_loss: 0.07875\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.70149\n",
            "epoch: 000 [ 276/2267 ( 12%)], train_loss: 0.07608\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.85074\n",
            "epoch: 000 [ 300/2267 ( 13%)], train_loss: 0.07477\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.75498\n",
            "epoch: 000 [ 324/2267 ( 14%)], train_loss: 0.07459\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.89577\n",
            "epoch: 000 [ 348/2267 ( 15%)], train_loss: 0.07430\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.80785\n",
            "epoch: 000 [ 372/2267 ( 16%)], train_loss: 0.07351\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72487\n",
            "epoch: 000 [ 396/2267 ( 17%)], train_loss: 0.07242\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.95157\n",
            "epoch: 000 [ 420/2267 ( 19%)], train_loss: 0.07225\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.00379\n",
            "epoch: 000 [ 444/2267 ( 20%)], train_loss: 0.07231\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72300\n",
            "epoch: 000 [ 468/2267 ( 21%)], train_loss: 0.07221\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.76588\n",
            "epoch: 000 [ 492/2267 ( 22%)], train_loss: 0.07124\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.75917\n",
            "epoch: 000 [ 516/2267 ( 23%)], train_loss: 0.07123\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78596\n",
            "epoch: 000 [ 540/2267 ( 24%)], train_loss: 0.07124\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.76803\n",
            "epoch: 000 [ 564/2267 ( 25%)], train_loss: 0.07062\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.79687\n",
            "epoch: 000 [ 588/2267 ( 26%)], train_loss: 0.07069\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69032\n",
            "0 epoch, best epoch was updated! valid_loss: 0.69032\n",
            "epoch: 000 [ 612/2267 ( 27%)], train_loss: 0.07056\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63331\n",
            "0 epoch, best epoch was updated! valid_loss: 0.63331\n",
            "epoch: 000 [ 636/2267 ( 28%)], train_loss: 0.07023\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78614\n",
            "epoch: 000 [ 660/2267 ( 29%)], train_loss: 0.06987\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.77514\n",
            "epoch: 000 [ 684/2267 ( 30%)], train_loss: 0.06961\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.81080\n",
            "epoch: 000 [ 708/2267 ( 31%)], train_loss: 0.06971\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.61392\n",
            "0 epoch, best epoch was updated! valid_loss: 0.61392\n",
            "epoch: 000 [ 732/2267 ( 32%)], train_loss: 0.06932\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.79422\n",
            "epoch: 000 [ 756/2267 ( 33%)], train_loss: 0.06899\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72256\n",
            "epoch: 000 [ 780/2267 ( 34%)], train_loss: 0.06914\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.81370\n",
            "epoch: 000 [ 804/2267 ( 35%)], train_loss: 0.06910\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73545\n",
            "epoch: 000 [ 828/2267 ( 37%)], train_loss: 0.06854\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69602\n",
            "epoch: 000 [ 852/2267 ( 38%)], train_loss: 0.06842\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73601\n",
            "epoch: 000 [ 876/2267 ( 39%)], train_loss: 0.06774\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.61012\n",
            "0 epoch, best epoch was updated! valid_loss: 0.61012\n",
            "epoch: 000 [ 900/2267 ( 40%)], train_loss: 0.06703\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.71780\n",
            "epoch: 000 [ 924/2267 ( 41%)], train_loss: 0.06643\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.57320\n",
            "0 epoch, best epoch was updated! valid_loss: 0.57320\n",
            "epoch: 000 [ 948/2267 ( 42%)], train_loss: 0.06589\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.62012\n",
            "epoch: 000 [ 972/2267 ( 43%)], train_loss: 0.06519\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.58066\n",
            "epoch: 000 [ 996/2267 ( 44%)], train_loss: 0.06472\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64464\n",
            "epoch: 000 [1020/2267 ( 45%)], train_loss: 0.06420\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64320\n",
            "epoch: 000 [1044/2267 ( 46%)], train_loss: 0.06381\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.60530\n",
            "epoch: 000 [1068/2267 ( 47%)], train_loss: 0.06369\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.74945\n",
            "epoch: 000 [1092/2267 ( 48%)], train_loss: 0.06339\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.74876\n",
            "epoch: 000 [1116/2267 ( 49%)], train_loss: 0.06342\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.70746\n",
            "epoch: 000 [1140/2267 ( 50%)], train_loss: 0.06339\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78945\n",
            "epoch: 000 [1164/2267 ( 51%)], train_loss: 0.06347\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72485\n",
            "epoch: 000 [1188/2267 ( 52%)], train_loss: 0.06351\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78201\n",
            "epoch: 000 [1212/2267 ( 53%)], train_loss: 0.06332\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.67758\n",
            "epoch: 000 [1236/2267 ( 55%)], train_loss: 0.06337\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63227\n",
            "epoch: 000 [1260/2267 ( 56%)], train_loss: 0.06314\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.65122\n",
            "epoch: 000 [1284/2267 ( 57%)], train_loss: 0.06308\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63040\n",
            "epoch: 000 [1308/2267 ( 58%)], train_loss: 0.06283\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.60285\n",
            "epoch: 000 [1332/2267 ( 59%)], train_loss: 0.06258\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.81628\n",
            "epoch: 000 [1356/2267 ( 60%)], train_loss: 0.06267\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78860\n",
            "epoch: 000 [1380/2267 ( 61%)], train_loss: 0.06253\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.77132\n",
            "epoch: 000 [1404/2267 ( 62%)], train_loss: 0.06269\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.39097\n",
            "epoch: 000 [1428/2267 ( 63%)], train_loss: 0.06328\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.34048\n",
            "epoch: 000 [1452/2267 ( 64%)], train_loss: 0.06402\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.97500\n",
            "epoch: 000 [1476/2267 ( 65%)], train_loss: 0.06437\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.05356\n",
            "epoch: 000 [1500/2267 ( 66%)], train_loss: 0.06488\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.02682\n",
            "epoch: 000 [1524/2267 ( 67%)], train_loss: 0.06555\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.08384\n",
            "epoch: 000 [1548/2267 ( 68%)], train_loss: 0.06578\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.08625\n",
            "epoch: 000 [1572/2267 ( 69%)], train_loss: 0.06603\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.03860\n",
            "epoch: 000 [1596/2267 ( 70%)], train_loss: 0.06649\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.04053\n",
            "epoch: 000 [1620/2267 ( 71%)], train_loss: 0.06676\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.15822\n",
            "epoch: 000 [1644/2267 ( 73%)], train_loss: 0.06746\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.10759\n",
            "epoch: 000 [1668/2267 ( 74%)], train_loss: 0.06750\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01555\n",
            "epoch: 000 [1692/2267 ( 75%)], train_loss: 0.06781\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.15574\n",
            "epoch: 000 [1716/2267 ( 76%)], train_loss: 0.06831\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.28685\n",
            "epoch: 000 [1740/2267 ( 77%)], train_loss: 0.06872\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.20921\n",
            "epoch: 000 [1764/2267 ( 78%)], train_loss: 0.06916\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.08326\n",
            "epoch: 000 [1788/2267 ( 79%)], train_loss: 0.06945\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01592\n",
            "epoch: 000 [1812/2267 ( 80%)], train_loss: 0.06961\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.10317\n",
            "epoch: 000 [1836/2267 ( 81%)], train_loss: 0.06961\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.10316\n",
            "epoch: 000 [1860/2267 ( 82%)], train_loss: 0.07018\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01492\n",
            "epoch: 000 [1884/2267 ( 83%)], train_loss: 0.07019\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.17782\n",
            "epoch: 000 [1908/2267 ( 84%)], train_loss: 0.07051\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.36108\n",
            "epoch: 000 [1932/2267 ( 85%)], train_loss: 0.07103\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.14773\n",
            "epoch: 000 [1956/2267 ( 86%)], train_loss: 0.07126\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.02176\n",
            "epoch: 000 [1980/2267 ( 87%)], train_loss: 0.07153\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.18312\n",
            "epoch: 000 [2004/2267 ( 88%)], train_loss: 0.07194\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.20437\n",
            "epoch: 000 [2028/2267 ( 89%)], train_loss: 0.07265\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01958\n",
            "epoch: 000 [2052/2267 ( 91%)], train_loss: 0.07306\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.20240\n",
            "epoch: 000 [2076/2267 ( 92%)], train_loss: 0.07332\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.27845\n",
            "epoch: 000 [2100/2267 ( 93%)], train_loss: 0.07365\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.10208\n",
            "epoch: 000 [2124/2267 ( 94%)], train_loss: 0.07399\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01751\n",
            "epoch: 000 [2148/2267 ( 95%)], train_loss: 0.07392\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.06930\n",
            "epoch: 000 [2172/2267 ( 96%)], train_loss: 0.07399\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.03970\n",
            "epoch: 000 [2196/2267 ( 97%)], train_loss: 0.07409\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01902\n",
            "epoch: 000 [2220/2267 ( 98%)], train_loss: 0.07419\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.06493\n",
            "epoch: 000 [2244/2267 ( 99%)], train_loss: 0.07447\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.06268\n",
            "epoch: 000 [2267/2267 (100%)], train_loss: 0.07479\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.01956\n",
            "epoch: 001 [  12/2267 (  1%)], train_loss: 0.09965\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01563\n",
            "epoch: 001 [  36/2267 (  2%)], train_loss: 0.09721\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01522\n",
            "epoch: 001 [  60/2267 (  3%)], train_loss: 0.08764\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01520\n",
            "epoch: 001 [  84/2267 (  4%)], train_loss: 0.08936\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.09146\n",
            "epoch: 001 [ 108/2267 (  5%)], train_loss: 0.08741\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.16459\n",
            "epoch: 001 [ 132/2267 (  6%)], train_loss: 0.08677\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.06066\n",
            "epoch: 001 [ 156/2267 (  7%)], train_loss: 0.08616\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03300\n",
            "epoch: 001 [ 180/2267 (  8%)], train_loss: 0.08649\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.15216\n",
            "epoch: 001 [ 204/2267 (  9%)], train_loss: 0.08843\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.10342\n",
            "epoch: 001 [ 228/2267 ( 10%)], train_loss: 0.08901\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01514\n",
            "epoch: 001 [ 252/2267 ( 11%)], train_loss: 0.09011\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.09866\n",
            "epoch: 001 [ 276/2267 ( 12%)], train_loss: 0.09019\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.11965\n",
            "epoch: 001 [ 300/2267 ( 13%)], train_loss: 0.09020\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.15007\n",
            "epoch: 001 [ 324/2267 ( 14%)], train_loss: 0.09047\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02046\n",
            "epoch: 001 [ 348/2267 ( 15%)], train_loss: 0.08987\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.13246\n",
            "epoch: 001 [ 372/2267 ( 16%)], train_loss: 0.09043\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.24552\n",
            "epoch: 001 [ 396/2267 ( 17%)], train_loss: 0.09153\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.09233\n",
            "epoch: 001 [ 420/2267 ( 19%)], train_loss: 0.09202\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02857\n",
            "epoch: 001 [ 444/2267 ( 20%)], train_loss: 0.09075\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.14075\n",
            "epoch: 001 [ 468/2267 ( 21%)], train_loss: 0.09144\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.19536\n",
            "epoch: 001 [ 492/2267 ( 22%)], train_loss: 0.09174\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.07830\n",
            "epoch: 001 [ 516/2267 ( 23%)], train_loss: 0.09210\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01646\n",
            "epoch: 001 [ 540/2267 ( 24%)], train_loss: 0.09211\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.12494\n",
            "epoch: 001 [ 564/2267 ( 25%)], train_loss: 0.09287\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.18075\n",
            "epoch: 001 [ 588/2267 ( 26%)], train_loss: 0.09257\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05501\n",
            "epoch: 001 [ 612/2267 ( 27%)], train_loss: 0.09196\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02157\n",
            "epoch: 001 [ 636/2267 ( 28%)], train_loss: 0.09228\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04128\n",
            "epoch: 001 [ 660/2267 ( 29%)], train_loss: 0.09215\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02809\n",
            "epoch: 001 [ 684/2267 ( 30%)], train_loss: 0.09221\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01516\n",
            "epoch: 001 [ 708/2267 ( 31%)], train_loss: 0.09253\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03456\n",
            "epoch: 001 [ 732/2267 ( 32%)], train_loss: 0.09256\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02320\n",
            "epoch: 001 [ 756/2267 ( 33%)], train_loss: 0.09261\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02036\n",
            "epoch: 001 [ 780/2267 ( 34%)], train_loss: 0.09249\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02193\n",
            "epoch: 001 [ 804/2267 ( 35%)], train_loss: 0.09217\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02361\n",
            "epoch: 001 [ 828/2267 ( 37%)], train_loss: 0.09178\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03254\n",
            "epoch: 001 [ 852/2267 ( 38%)], train_loss: 0.09121\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03292\n",
            "epoch: 001 [ 876/2267 ( 39%)], train_loss: 0.09090\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01522\n",
            "epoch: 001 [ 900/2267 ( 40%)], train_loss: 0.09097\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01689\n",
            "epoch: 001 [ 924/2267 ( 41%)], train_loss: 0.09065\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01497\n",
            "epoch: 001 [ 948/2267 ( 42%)], train_loss: 0.09069\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01518\n",
            "epoch: 001 [ 972/2267 ( 43%)], train_loss: 0.09063\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04344\n",
            "epoch: 001 [ 996/2267 ( 44%)], train_loss: 0.09061\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.12918\n",
            "epoch: 001 [1020/2267 ( 45%)], train_loss: 0.09066\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.13632\n",
            "epoch: 001 [1044/2267 ( 46%)], train_loss: 0.09072\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03002\n",
            "epoch: 001 [1068/2267 ( 47%)], train_loss: 0.09041\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01794\n",
            "epoch: 001 [1092/2267 ( 48%)], train_loss: 0.09027\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.10468\n",
            "epoch: 001 [1116/2267 ( 49%)], train_loss: 0.09042\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.16052\n",
            "epoch: 001 [1140/2267 ( 50%)], train_loss: 0.09048\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04165\n",
            "epoch: 001 [1164/2267 ( 51%)], train_loss: 0.09023\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03217\n",
            "epoch: 001 [1188/2267 ( 52%)], train_loss: 0.09038\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.07480\n",
            "epoch: 001 [1212/2267 ( 53%)], train_loss: 0.09063\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03956\n",
            "epoch: 001 [1236/2267 ( 55%)], train_loss: 0.09050\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01710\n",
            "epoch: 001 [1260/2267 ( 56%)], train_loss: 0.09032\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01487\n",
            "epoch: 001 [1284/2267 ( 57%)], train_loss: 0.09002\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01652\n",
            "epoch: 001 [1308/2267 ( 58%)], train_loss: 0.08999\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01514\n",
            "epoch: 001 [1332/2267 ( 59%)], train_loss: 0.08990\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01559\n",
            "epoch: 001 [1356/2267 ( 60%)], train_loss: 0.09006\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02528\n",
            "epoch: 001 [1380/2267 ( 61%)], train_loss: 0.09000\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05122\n",
            "epoch: 001 [1404/2267 ( 62%)], train_loss: 0.08976\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05960\n",
            "epoch: 001 [1428/2267 ( 63%)], train_loss: 0.08977\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02935\n",
            "epoch: 001 [1452/2267 ( 64%)], train_loss: 0.08949\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01794\n",
            "epoch: 001 [1476/2267 ( 65%)], train_loss: 0.08957\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02629\n",
            "epoch: 001 [1500/2267 ( 66%)], train_loss: 0.08961\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01910\n",
            "epoch: 001 [1524/2267 ( 67%)], train_loss: 0.08989\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02683\n",
            "epoch: 001 [1548/2267 ( 68%)], train_loss: 0.08986\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03093\n",
            "epoch: 001 [1572/2267 ( 69%)], train_loss: 0.08986\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01670\n",
            "epoch: 001 [1596/2267 ( 70%)], train_loss: 0.08975\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01606\n",
            "epoch: 001 [1620/2267 ( 71%)], train_loss: 0.08961\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05712\n",
            "epoch: 001 [1644/2267 ( 73%)], train_loss: 0.08966\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05001\n",
            "epoch: 001 [1668/2267 ( 74%)], train_loss: 0.08978\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01490\n",
            "epoch: 001 [1692/2267 ( 75%)], train_loss: 0.08972\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02785\n",
            "epoch: 001 [1716/2267 ( 76%)], train_loss: 0.08982\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01568\n",
            "epoch: 001 [1740/2267 ( 77%)], train_loss: 0.08988\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03035\n",
            "epoch: 001 [1764/2267 ( 78%)], train_loss: 0.08960\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01731\n",
            "epoch: 001 [1788/2267 ( 79%)], train_loss: 0.08955\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01488\n",
            "epoch: 001 [1812/2267 ( 80%)], train_loss: 0.08937\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02610\n",
            "epoch: 001 [1836/2267 ( 81%)], train_loss: 0.08917\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04768\n",
            "epoch: 001 [1860/2267 ( 82%)], train_loss: 0.08908\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05912\n",
            "epoch: 001 [1884/2267 ( 83%)], train_loss: 0.08897\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04058\n",
            "epoch: 001 [1908/2267 ( 84%)], train_loss: 0.08895\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01672\n",
            "epoch: 001 [1932/2267 ( 85%)], train_loss: 0.08886\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03659\n",
            "epoch: 001 [1956/2267 ( 86%)], train_loss: 0.08884\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01826\n",
            "epoch: 001 [1980/2267 ( 87%)], train_loss: 0.08879\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01803\n",
            "epoch: 001 [2004/2267 ( 88%)], train_loss: 0.08884\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01744\n",
            "epoch: 001 [2028/2267 ( 89%)], train_loss: 0.08864\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01512\n",
            "epoch: 001 [2052/2267 ( 91%)], train_loss: 0.08850\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02366\n",
            "epoch: 001 [2076/2267 ( 92%)], train_loss: 0.08847\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01490\n",
            "epoch: 001 [2100/2267 ( 93%)], train_loss: 0.08834\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02907\n",
            "epoch: 001 [2124/2267 ( 94%)], train_loss: 0.08831\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02729\n",
            "epoch: 001 [2148/2267 ( 95%)], train_loss: 0.08828\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.02261\n",
            "epoch: 001 [2172/2267 ( 96%)], train_loss: 0.08828\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04297\n",
            "epoch: 001 [2196/2267 ( 97%)], train_loss: 0.08804\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.01561\n",
            "epoch: 001 [2220/2267 ( 98%)], train_loss: 0.08788\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.04347\n",
            "epoch: 001 [2244/2267 ( 99%)], train_loss: 0.08803\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.05866\n",
            "epoch: 001 [2267/2267 (100%)], train_loss: 0.08840\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 1.03645\n",
            "epoch: 002 [  12/2267 (  1%)], train_loss: 0.08183\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01945\n",
            "epoch: 002 [  36/2267 (  2%)], train_loss: 0.08496\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01554\n",
            "epoch: 002 [  60/2267 (  3%)], train_loss: 0.09184\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04238\n",
            "epoch: 002 [  84/2267 (  4%)], train_loss: 0.09052\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02594\n",
            "epoch: 002 [ 108/2267 (  5%)], train_loss: 0.08964\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03929\n",
            "epoch: 002 [ 132/2267 (  6%)], train_loss: 0.08915\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02288\n",
            "epoch: 002 [ 156/2267 (  7%)], train_loss: 0.08921\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01497\n",
            "epoch: 002 [ 180/2267 (  8%)], train_loss: 0.08679\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02509\n",
            "epoch: 002 [ 204/2267 (  9%)], train_loss: 0.08505\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.05834\n",
            "epoch: 002 [ 228/2267 ( 10%)], train_loss: 0.08535\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03940\n",
            "epoch: 002 [ 252/2267 ( 11%)], train_loss: 0.08642\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01547\n",
            "epoch: 002 [ 276/2267 ( 12%)], train_loss: 0.08616\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02921\n",
            "epoch: 002 [ 300/2267 ( 13%)], train_loss: 0.08683\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.07619\n",
            "epoch: 002 [ 324/2267 ( 14%)], train_loss: 0.08712\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.08372\n",
            "epoch: 002 [ 348/2267 ( 15%)], train_loss: 0.08706\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02996\n",
            "epoch: 002 [ 372/2267 ( 16%)], train_loss: 0.08627\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01616\n",
            "epoch: 002 [ 396/2267 ( 17%)], train_loss: 0.08685\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01697\n",
            "epoch: 002 [ 420/2267 ( 19%)], train_loss: 0.08602\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01502\n",
            "epoch: 002 [ 444/2267 ( 20%)], train_loss: 0.08630\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02076\n",
            "epoch: 002 [ 468/2267 ( 21%)], train_loss: 0.08629\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01583\n",
            "epoch: 002 [ 492/2267 ( 22%)], train_loss: 0.08522\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01806\n",
            "epoch: 002 [ 516/2267 ( 23%)], train_loss: 0.08535\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01873\n",
            "epoch: 002 [ 540/2267 ( 24%)], train_loss: 0.08523\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01528\n",
            "epoch: 002 [ 564/2267 ( 25%)], train_loss: 0.08435\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02381\n",
            "epoch: 002 [ 588/2267 ( 26%)], train_loss: 0.08448\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03376\n",
            "epoch: 002 [ 612/2267 ( 27%)], train_loss: 0.08463\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03576\n",
            "epoch: 002 [ 636/2267 ( 28%)], train_loss: 0.08435\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01615\n",
            "epoch: 002 [ 660/2267 ( 29%)], train_loss: 0.08398\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01755\n",
            "epoch: 002 [ 684/2267 ( 30%)], train_loss: 0.08338\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04269\n",
            "epoch: 002 [ 708/2267 ( 31%)], train_loss: 0.08315\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03788\n",
            "epoch: 002 [ 732/2267 ( 32%)], train_loss: 0.08378\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01521\n",
            "epoch: 002 [ 756/2267 ( 33%)], train_loss: 0.08380\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02241\n",
            "epoch: 002 [ 780/2267 ( 34%)], train_loss: 0.08335\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02167\n",
            "epoch: 002 [ 804/2267 ( 35%)], train_loss: 0.08353\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01488\n",
            "epoch: 002 [ 828/2267 ( 37%)], train_loss: 0.08318\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01527\n",
            "epoch: 002 [ 852/2267 ( 38%)], train_loss: 0.08268\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02104\n",
            "epoch: 002 [ 876/2267 ( 39%)], train_loss: 0.08320\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01670\n",
            "epoch: 002 [ 900/2267 ( 40%)], train_loss: 0.08330\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01716\n",
            "epoch: 002 [ 924/2267 ( 41%)], train_loss: 0.08373\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01782\n",
            "epoch: 002 [ 948/2267 ( 42%)], train_loss: 0.08309\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03108\n",
            "epoch: 002 [ 972/2267 ( 43%)], train_loss: 0.08317\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.06170\n",
            "epoch: 002 [ 996/2267 ( 44%)], train_loss: 0.08333\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.06220\n",
            "epoch: 002 [1020/2267 ( 45%)], train_loss: 0.08344\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04306\n",
            "epoch: 002 [1044/2267 ( 46%)], train_loss: 0.08336\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01866\n",
            "epoch: 002 [1068/2267 ( 47%)], train_loss: 0.08350\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02415\n",
            "epoch: 002 [1092/2267 ( 48%)], train_loss: 0.08354\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01564\n",
            "epoch: 002 [1116/2267 ( 49%)], train_loss: 0.08363\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01658\n",
            "epoch: 002 [1140/2267 ( 50%)], train_loss: 0.08410\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03763\n",
            "epoch: 002 [1164/2267 ( 51%)], train_loss: 0.08379\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02888\n",
            "epoch: 002 [1188/2267 ( 52%)], train_loss: 0.08388\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02127\n",
            "epoch: 002 [1212/2267 ( 53%)], train_loss: 0.08451\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02187\n",
            "epoch: 002 [1236/2267 ( 55%)], train_loss: 0.08468\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01677\n",
            "epoch: 002 [1260/2267 ( 56%)], train_loss: 0.08471\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.06732\n",
            "epoch: 002 [1284/2267 ( 57%)], train_loss: 0.08487\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.15443\n",
            "epoch: 002 [1308/2267 ( 58%)], train_loss: 0.08535\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.10383\n",
            "epoch: 002 [1332/2267 ( 59%)], train_loss: 0.08569\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02674\n",
            "epoch: 002 [1356/2267 ( 60%)], train_loss: 0.08583\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02666\n",
            "epoch: 002 [1380/2267 ( 61%)], train_loss: 0.08568\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.07030\n",
            "epoch: 002 [1404/2267 ( 62%)], train_loss: 0.08575\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04604\n",
            "epoch: 002 [1428/2267 ( 63%)], train_loss: 0.08559\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01630\n",
            "epoch: 002 [1452/2267 ( 64%)], train_loss: 0.08583\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03389\n",
            "epoch: 002 [1476/2267 ( 65%)], train_loss: 0.08586\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01768\n",
            "epoch: 002 [1500/2267 ( 66%)], train_loss: 0.08571\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01811\n",
            "epoch: 002 [1524/2267 ( 67%)], train_loss: 0.08579\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.08021\n",
            "epoch: 002 [1548/2267 ( 68%)], train_loss: 0.08565\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.08303\n",
            "epoch: 002 [1572/2267 ( 69%)], train_loss: 0.08580\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01504\n",
            "epoch: 002 [1596/2267 ( 70%)], train_loss: 0.08599\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.09746\n",
            "epoch: 002 [1620/2267 ( 71%)], train_loss: 0.08613\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.18039\n",
            "epoch: 002 [1644/2267 ( 73%)], train_loss: 0.08622\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.08966\n",
            "epoch: 002 [1668/2267 ( 74%)], train_loss: 0.08606\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01502\n",
            "epoch: 002 [1692/2267 ( 75%)], train_loss: 0.08618\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.06841\n",
            "epoch: 002 [1716/2267 ( 76%)], train_loss: 0.08610\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.05854\n",
            "epoch: 002 [1740/2267 ( 77%)], train_loss: 0.08618\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02844\n",
            "epoch: 002 [1764/2267 ( 78%)], train_loss: 0.08599\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01768\n",
            "epoch: 002 [1788/2267 ( 79%)], train_loss: 0.08585\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.05611\n",
            "epoch: 002 [1812/2267 ( 80%)], train_loss: 0.08608\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03021\n",
            "epoch: 002 [1836/2267 ( 81%)], train_loss: 0.08605\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02907\n",
            "epoch: 002 [1860/2267 ( 82%)], train_loss: 0.08597\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03902\n",
            "epoch: 002 [1884/2267 ( 83%)], train_loss: 0.08574\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02460\n",
            "epoch: 002 [1908/2267 ( 84%)], train_loss: 0.08599\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02472\n",
            "epoch: 002 [1932/2267 ( 85%)], train_loss: 0.08569\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04992\n",
            "epoch: 002 [1956/2267 ( 86%)], train_loss: 0.08569\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.04612\n",
            "epoch: 002 [1980/2267 ( 87%)], train_loss: 0.08557\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02689\n",
            "epoch: 002 [2004/2267 ( 88%)], train_loss: 0.08539\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01713\n",
            "epoch: 002 [2028/2267 ( 89%)], train_loss: 0.08540\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01943\n",
            "epoch: 002 [2052/2267 ( 91%)], train_loss: 0.08549\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03496\n",
            "epoch: 002 [2076/2267 ( 92%)], train_loss: 0.08575\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01509\n",
            "epoch: 002 [2100/2267 ( 93%)], train_loss: 0.08581\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.08279\n",
            "epoch: 002 [2124/2267 ( 94%)], train_loss: 0.08607\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.18694\n",
            "epoch: 002 [2148/2267 ( 95%)], train_loss: 0.08614\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.13192\n",
            "epoch: 002 [2172/2267 ( 96%)], train_loss: 0.08634\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.03190\n",
            "epoch: 002 [2196/2267 ( 97%)], train_loss: 0.08644\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01560\n",
            "epoch: 002 [2220/2267 ( 98%)], train_loss: 0.08641\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01703\n",
            "epoch: 002 [2244/2267 ( 99%)], train_loss: 0.08611\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.01767\n",
            "epoch: 002 [2267/2267 (100%)], train_loss: 0.08630\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 1.02510\n",
            "epoch: 003 [  12/2267 (  1%)], train_loss: 0.04863\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03572\n",
            "epoch: 003 [  36/2267 (  2%)], train_loss: 0.07489\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02000\n",
            "epoch: 003 [  60/2267 (  3%)], train_loss: 0.07404\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01488\n",
            "epoch: 003 [  84/2267 (  4%)], train_loss: 0.07660\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02481\n",
            "epoch: 003 [ 108/2267 (  5%)], train_loss: 0.07708\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.06394\n",
            "epoch: 003 [ 132/2267 (  6%)], train_loss: 0.07769\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04223\n",
            "epoch: 003 [ 156/2267 (  7%)], train_loss: 0.07737\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01493\n",
            "epoch: 003 [ 180/2267 (  8%)], train_loss: 0.08133\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02353\n",
            "epoch: 003 [ 204/2267 (  9%)], train_loss: 0.08277\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.06177\n",
            "epoch: 003 [ 228/2267 ( 10%)], train_loss: 0.08178\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.09282\n",
            "epoch: 003 [ 252/2267 ( 11%)], train_loss: 0.08142\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05192\n",
            "epoch: 003 [ 276/2267 ( 12%)], train_loss: 0.08126\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01531\n",
            "epoch: 003 [ 300/2267 ( 13%)], train_loss: 0.08266\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05256\n",
            "epoch: 003 [ 324/2267 ( 14%)], train_loss: 0.08232\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.06837\n",
            "epoch: 003 [ 348/2267 ( 15%)], train_loss: 0.08197\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02610\n",
            "epoch: 003 [ 372/2267 ( 16%)], train_loss: 0.08288\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02284\n",
            "epoch: 003 [ 396/2267 ( 17%)], train_loss: 0.08289\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.12735\n",
            "epoch: 003 [ 420/2267 ( 19%)], train_loss: 0.08238\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.24991\n",
            "epoch: 003 [ 444/2267 ( 20%)], train_loss: 0.08345\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.24791\n",
            "epoch: 003 [ 468/2267 ( 21%)], train_loss: 0.08536\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.09446\n",
            "epoch: 003 [ 492/2267 ( 22%)], train_loss: 0.08544\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01727\n",
            "epoch: 003 [ 516/2267 ( 23%)], train_loss: 0.08612\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.11588\n",
            "epoch: 003 [ 540/2267 ( 24%)], train_loss: 0.08736\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.14239\n",
            "epoch: 003 [ 564/2267 ( 25%)], train_loss: 0.08853\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03113\n",
            "epoch: 003 [ 588/2267 ( 26%)], train_loss: 0.08830\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04297\n",
            "epoch: 003 [ 612/2267 ( 27%)], train_loss: 0.08797\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.11101\n",
            "epoch: 003 [ 636/2267 ( 28%)], train_loss: 0.08873\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07934\n",
            "epoch: 003 [ 660/2267 ( 29%)], train_loss: 0.08824\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04649\n",
            "epoch: 003 [ 684/2267 ( 30%)], train_loss: 0.08786\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01904\n",
            "epoch: 003 [ 708/2267 ( 31%)], train_loss: 0.08689\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02110\n",
            "epoch: 003 [ 732/2267 ( 32%)], train_loss: 0.08771\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01513\n",
            "epoch: 003 [ 756/2267 ( 33%)], train_loss: 0.08737\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03362\n",
            "epoch: 003 [ 780/2267 ( 34%)], train_loss: 0.08746\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07305\n",
            "epoch: 003 [ 804/2267 ( 35%)], train_loss: 0.08760\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05401\n",
            "epoch: 003 [ 828/2267 ( 37%)], train_loss: 0.08751\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01551\n",
            "epoch: 003 [ 852/2267 ( 38%)], train_loss: 0.08736\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07805\n",
            "epoch: 003 [ 876/2267 ( 39%)], train_loss: 0.08688\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.12475\n",
            "epoch: 003 [ 900/2267 ( 40%)], train_loss: 0.08676\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04613\n",
            "epoch: 003 [ 924/2267 ( 41%)], train_loss: 0.08681\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01515\n",
            "epoch: 003 [ 948/2267 ( 42%)], train_loss: 0.08676\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05305\n",
            "epoch: 003 [ 972/2267 ( 43%)], train_loss: 0.08697\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.09231\n",
            "epoch: 003 [ 996/2267 ( 44%)], train_loss: 0.08685\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.13474\n",
            "epoch: 003 [1020/2267 ( 45%)], train_loss: 0.08731\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.08146\n",
            "epoch: 003 [1044/2267 ( 46%)], train_loss: 0.08674\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02631\n",
            "epoch: 003 [1068/2267 ( 47%)], train_loss: 0.08687\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04617\n",
            "epoch: 003 [1092/2267 ( 48%)], train_loss: 0.08684\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.08974\n",
            "epoch: 003 [1116/2267 ( 49%)], train_loss: 0.08745\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05523\n",
            "epoch: 003 [1140/2267 ( 50%)], train_loss: 0.08730\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01603\n",
            "epoch: 003 [1164/2267 ( 51%)], train_loss: 0.08749\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03110\n",
            "epoch: 003 [1188/2267 ( 52%)], train_loss: 0.08762\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.06050\n",
            "epoch: 003 [1212/2267 ( 53%)], train_loss: 0.08784\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04094\n",
            "epoch: 003 [1236/2267 ( 55%)], train_loss: 0.08794\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02099\n",
            "epoch: 003 [1260/2267 ( 56%)], train_loss: 0.08802\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01506\n",
            "epoch: 003 [1284/2267 ( 57%)], train_loss: 0.08773\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01646\n",
            "epoch: 003 [1308/2267 ( 58%)], train_loss: 0.08786\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04423\n",
            "epoch: 003 [1332/2267 ( 59%)], train_loss: 0.08808\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02693\n",
            "epoch: 003 [1356/2267 ( 60%)], train_loss: 0.08794\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01674\n",
            "epoch: 003 [1380/2267 ( 61%)], train_loss: 0.08788\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01521\n",
            "epoch: 003 [1404/2267 ( 62%)], train_loss: 0.08824\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01489\n",
            "epoch: 003 [1428/2267 ( 63%)], train_loss: 0.08824\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01499\n",
            "epoch: 003 [1452/2267 ( 64%)], train_loss: 0.08806\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01519\n",
            "epoch: 003 [1476/2267 ( 65%)], train_loss: 0.08802\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02807\n",
            "epoch: 003 [1500/2267 ( 66%)], train_loss: 0.08806\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03232\n",
            "epoch: 003 [1524/2267 ( 67%)], train_loss: 0.08796\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01962\n",
            "epoch: 003 [1548/2267 ( 68%)], train_loss: 0.08753\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01506\n",
            "epoch: 003 [1572/2267 ( 69%)], train_loss: 0.08722\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03507\n",
            "epoch: 003 [1596/2267 ( 70%)], train_loss: 0.08729\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.06162\n",
            "epoch: 003 [1620/2267 ( 71%)], train_loss: 0.08732\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02163\n",
            "epoch: 003 [1644/2267 ( 73%)], train_loss: 0.08722\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03523\n",
            "epoch: 003 [1668/2267 ( 74%)], train_loss: 0.08753\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05221\n",
            "epoch: 003 [1692/2267 ( 75%)], train_loss: 0.08740\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02591\n",
            "epoch: 003 [1716/2267 ( 76%)], train_loss: 0.08769\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02188\n",
            "epoch: 003 [1740/2267 ( 77%)], train_loss: 0.08759\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07446\n",
            "epoch: 003 [1764/2267 ( 78%)], train_loss: 0.08773\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07483\n",
            "epoch: 003 [1788/2267 ( 79%)], train_loss: 0.08769\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04332\n",
            "epoch: 003 [1812/2267 ( 80%)], train_loss: 0.08767\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01491\n",
            "epoch: 003 [1836/2267 ( 81%)], train_loss: 0.08747\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05001\n",
            "epoch: 003 [1860/2267 ( 82%)], train_loss: 0.08739\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.07344\n",
            "epoch: 003 [1884/2267 ( 83%)], train_loss: 0.08720\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02772\n",
            "epoch: 003 [1908/2267 ( 84%)], train_loss: 0.08711\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01744\n",
            "epoch: 003 [1932/2267 ( 85%)], train_loss: 0.08719\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04430\n",
            "epoch: 003 [1956/2267 ( 86%)], train_loss: 0.08706\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05511\n",
            "epoch: 003 [1980/2267 ( 87%)], train_loss: 0.08703\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01813\n",
            "epoch: 003 [2004/2267 ( 88%)], train_loss: 0.08697\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01513\n",
            "epoch: 003 [2028/2267 ( 89%)], train_loss: 0.08677\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01492\n",
            "epoch: 003 [2052/2267 ( 91%)], train_loss: 0.08703\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01943\n",
            "epoch: 003 [2076/2267 ( 92%)], train_loss: 0.08678\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.04387\n",
            "epoch: 003 [2100/2267 ( 93%)], train_loss: 0.08674\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05748\n",
            "epoch: 003 [2124/2267 ( 94%)], train_loss: 0.08670\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.05947\n",
            "epoch: 003 [2148/2267 ( 95%)], train_loss: 0.08647\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03571\n",
            "epoch: 003 [2172/2267 ( 96%)], train_loss: 0.08647\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.02189\n",
            "epoch: 003 [2196/2267 ( 97%)], train_loss: 0.08666\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01510\n",
            "epoch: 003 [2220/2267 ( 98%)], train_loss: 0.08680\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.01525\n",
            "epoch: 003 [2244/2267 ( 99%)], train_loss: 0.08681\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03114\n",
            "epoch: 003 [2267/2267 (100%)], train_loss: 0.08709\n",
            "----Validation Results Summary----\n",
            "Epoch: [3] train_loss: 1.03304\n",
            "epoch: 004 [  12/2267 (  1%)], train_loss: 0.12489\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03755\n",
            "epoch: 004 [  36/2267 (  2%)], train_loss: 0.09544\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03328\n",
            "epoch: 004 [  60/2267 (  3%)], train_loss: 0.09110\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01947\n",
            "epoch: 004 [  84/2267 (  4%)], train_loss: 0.09353\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01687\n",
            "epoch: 004 [ 108/2267 (  5%)], train_loss: 0.09345\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01627\n",
            "epoch: 004 [ 132/2267 (  6%)], train_loss: 0.09481\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01681\n",
            "epoch: 004 [ 156/2267 (  7%)], train_loss: 0.09106\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01497\n",
            "epoch: 004 [ 180/2267 (  8%)], train_loss: 0.08827\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01496\n",
            "epoch: 004 [ 204/2267 (  9%)], train_loss: 0.08714\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01850\n",
            "epoch: 004 [ 228/2267 ( 10%)], train_loss: 0.08904\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03128\n",
            "epoch: 004 [ 252/2267 ( 11%)], train_loss: 0.08849\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03289\n",
            "epoch: 004 [ 276/2267 ( 12%)], train_loss: 0.08684\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01830\n",
            "epoch: 004 [ 300/2267 ( 13%)], train_loss: 0.08750\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01788\n",
            "epoch: 004 [ 324/2267 ( 14%)], train_loss: 0.08738\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02949\n",
            "epoch: 004 [ 348/2267 ( 15%)], train_loss: 0.08710\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03654\n",
            "epoch: 004 [ 372/2267 ( 16%)], train_loss: 0.08785\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02825\n",
            "epoch: 004 [ 396/2267 ( 17%)], train_loss: 0.08816\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01667\n",
            "epoch: 004 [ 420/2267 ( 19%)], train_loss: 0.08811\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01534\n",
            "epoch: 004 [ 444/2267 ( 20%)], train_loss: 0.08720\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01550\n",
            "epoch: 004 [ 468/2267 ( 21%)], train_loss: 0.08630\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.04166\n",
            "epoch: 004 [ 492/2267 ( 22%)], train_loss: 0.08662\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.07460\n",
            "epoch: 004 [ 516/2267 ( 23%)], train_loss: 0.08691\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.04726\n",
            "epoch: 004 [ 540/2267 ( 24%)], train_loss: 0.08667\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01511\n",
            "epoch: 004 [ 564/2267 ( 25%)], train_loss: 0.08635\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.06722\n",
            "epoch: 004 [ 588/2267 ( 26%)], train_loss: 0.08643\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.12823\n",
            "epoch: 004 [ 612/2267 ( 27%)], train_loss: 0.08609\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.12707\n",
            "epoch: 004 [ 636/2267 ( 28%)], train_loss: 0.08622\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.07784\n",
            "epoch: 004 [ 660/2267 ( 29%)], train_loss: 0.08688\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01921\n",
            "epoch: 004 [ 684/2267 ( 30%)], train_loss: 0.08725\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03175\n",
            "epoch: 004 [ 708/2267 ( 31%)], train_loss: 0.08723\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02672\n",
            "epoch: 004 [ 732/2267 ( 32%)], train_loss: 0.08702\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01745\n",
            "epoch: 004 [ 756/2267 ( 33%)], train_loss: 0.08681\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.05584\n",
            "epoch: 004 [ 780/2267 ( 34%)], train_loss: 0.08773\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.09153\n",
            "epoch: 004 [ 804/2267 ( 35%)], train_loss: 0.08807\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.05239\n",
            "epoch: 004 [ 828/2267 ( 37%)], train_loss: 0.08797\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01716\n",
            "epoch: 004 [ 852/2267 ( 38%)], train_loss: 0.08792\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01774\n",
            "epoch: 004 [ 876/2267 ( 39%)], train_loss: 0.08738\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01653\n",
            "epoch: 004 [ 900/2267 ( 40%)], train_loss: 0.08722\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01879\n",
            "epoch: 004 [ 924/2267 ( 41%)], train_loss: 0.08724\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02238\n",
            "epoch: 004 [ 948/2267 ( 42%)], train_loss: 0.08783\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01730\n",
            "epoch: 004 [ 972/2267 ( 43%)], train_loss: 0.08748\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01550\n",
            "epoch: 004 [ 996/2267 ( 44%)], train_loss: 0.08759\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03078\n",
            "epoch: 004 [1020/2267 ( 45%)], train_loss: 0.08747\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02440\n",
            "epoch: 004 [1044/2267 ( 46%)], train_loss: 0.08732\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01510\n",
            "epoch: 004 [1068/2267 ( 47%)], train_loss: 0.08725\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03389\n",
            "epoch: 004 [1092/2267 ( 48%)], train_loss: 0.08692\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.07128\n",
            "epoch: 004 [1116/2267 ( 49%)], train_loss: 0.08673\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.07799\n",
            "epoch: 004 [1140/2267 ( 50%)], train_loss: 0.08646\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.06369\n",
            "epoch: 004 [1164/2267 ( 51%)], train_loss: 0.08642\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02487\n",
            "epoch: 004 [1188/2267 ( 52%)], train_loss: 0.08688\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01751\n",
            "epoch: 004 [1212/2267 ( 53%)], train_loss: 0.08715\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.04888\n",
            "epoch: 004 [1236/2267 ( 55%)], train_loss: 0.08741\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.05334\n",
            "epoch: 004 [1260/2267 ( 56%)], train_loss: 0.08731\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02554\n",
            "epoch: 004 [1284/2267 ( 57%)], train_loss: 0.08712\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01918\n",
            "epoch: 004 [1308/2267 ( 58%)], train_loss: 0.08707\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.05921\n",
            "epoch: 004 [1332/2267 ( 59%)], train_loss: 0.08689\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.06428\n",
            "epoch: 004 [1356/2267 ( 60%)], train_loss: 0.08694\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.05969\n",
            "epoch: 004 [1380/2267 ( 61%)], train_loss: 0.08696\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02638\n",
            "epoch: 004 [1404/2267 ( 62%)], train_loss: 0.08667\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02176\n",
            "epoch: 004 [1428/2267 ( 63%)], train_loss: 0.08691\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03819\n",
            "epoch: 004 [1452/2267 ( 64%)], train_loss: 0.08666\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02472\n",
            "epoch: 004 [1476/2267 ( 65%)], train_loss: 0.08650\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01738\n",
            "epoch: 004 [1500/2267 ( 66%)], train_loss: 0.08632\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03754\n",
            "epoch: 004 [1524/2267 ( 67%)], train_loss: 0.08633\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02291\n",
            "epoch: 004 [1548/2267 ( 68%)], train_loss: 0.08634\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02026\n",
            "epoch: 004 [1572/2267 ( 69%)], train_loss: 0.08647\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01539\n",
            "epoch: 004 [1596/2267 ( 70%)], train_loss: 0.08661\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01572\n",
            "epoch: 004 [1620/2267 ( 71%)], train_loss: 0.08658\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01635\n",
            "epoch: 004 [1644/2267 ( 73%)], train_loss: 0.08643\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01505\n",
            "epoch: 004 [1668/2267 ( 74%)], train_loss: 0.08651\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02210\n",
            "epoch: 004 [1692/2267 ( 75%)], train_loss: 0.08671\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.06693\n",
            "epoch: 004 [1716/2267 ( 76%)], train_loss: 0.08667\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.09220\n",
            "epoch: 004 [1740/2267 ( 77%)], train_loss: 0.08673\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.08332\n",
            "epoch: 004 [1764/2267 ( 78%)], train_loss: 0.08675\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.04858\n",
            "epoch: 004 [1788/2267 ( 79%)], train_loss: 0.08681\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01579\n",
            "epoch: 004 [1812/2267 ( 80%)], train_loss: 0.08652\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02200\n",
            "epoch: 004 [1836/2267 ( 81%)], train_loss: 0.08649\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.04397\n",
            "epoch: 004 [1860/2267 ( 82%)], train_loss: 0.08671\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.03310\n",
            "epoch: 004 [1884/2267 ( 83%)], train_loss: 0.08654\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02409\n",
            "epoch: 004 [1908/2267 ( 84%)], train_loss: 0.08645\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01657\n",
            "epoch: 004 [1932/2267 ( 85%)], train_loss: 0.08652\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01708\n",
            "epoch: 004 [1956/2267 ( 86%)], train_loss: 0.08633\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01996\n",
            "epoch: 004 [1980/2267 ( 87%)], train_loss: 0.08610\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01496\n",
            "epoch: 004 [2004/2267 ( 88%)], train_loss: 0.08605\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01510\n",
            "epoch: 004 [2028/2267 ( 89%)], train_loss: 0.08617\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01581\n",
            "epoch: 004 [2052/2267 ( 91%)], train_loss: 0.08627\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01932\n",
            "epoch: 004 [2076/2267 ( 92%)], train_loss: 0.08631\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02325\n",
            "epoch: 004 [2100/2267 ( 93%)], train_loss: 0.08639\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01979\n",
            "epoch: 004 [2124/2267 ( 94%)], train_loss: 0.08625\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01590\n",
            "epoch: 004 [2148/2267 ( 95%)], train_loss: 0.08629\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01489\n",
            "epoch: 004 [2172/2267 ( 96%)], train_loss: 0.08633\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01741\n",
            "epoch: 004 [2196/2267 ( 97%)], train_loss: 0.08642\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01563\n",
            "epoch: 004 [2220/2267 ( 98%)], train_loss: 0.08633\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01510\n",
            "epoch: 004 [2244/2267 ( 99%)], train_loss: 0.08639\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.01624\n",
            "epoch: 004 [2267/2267 (100%)], train_loss: 0.08638\n",
            "----Validation Results Summary----\n",
            "Epoch: [4] train_loss: 1.02005\n",
            "epoch: 005 [  12/2267 (  1%)], train_loss: 0.13829\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01944\n",
            "epoch: 005 [  36/2267 (  2%)], train_loss: 0.09303\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01547\n",
            "epoch: 005 [  60/2267 (  3%)], train_loss: 0.08729\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01501\n",
            "epoch: 005 [  84/2267 (  4%)], train_loss: 0.09052\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01537\n",
            "epoch: 005 [ 108/2267 (  5%)], train_loss: 0.08661\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02514\n",
            "epoch: 005 [ 132/2267 (  6%)], train_loss: 0.08388\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03123\n",
            "epoch: 005 [ 156/2267 (  7%)], train_loss: 0.08315\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03642\n",
            "epoch: 005 [ 180/2267 (  8%)], train_loss: 0.08180\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03519\n",
            "epoch: 005 [ 204/2267 (  9%)], train_loss: 0.07899\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02100\n",
            "epoch: 005 [ 228/2267 ( 10%)], train_loss: 0.08050\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01598\n",
            "epoch: 005 [ 252/2267 ( 11%)], train_loss: 0.08088\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01490\n",
            "epoch: 005 [ 276/2267 ( 12%)], train_loss: 0.08194\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01772\n",
            "epoch: 005 [ 300/2267 ( 13%)], train_loss: 0.08169\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02504\n",
            "epoch: 005 [ 324/2267 ( 14%)], train_loss: 0.08125\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03563\n",
            "epoch: 005 [ 348/2267 ( 15%)], train_loss: 0.08243\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02438\n",
            "epoch: 005 [ 372/2267 ( 16%)], train_loss: 0.08280\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01512\n",
            "epoch: 005 [ 396/2267 ( 17%)], train_loss: 0.08304\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03723\n",
            "epoch: 005 [ 420/2267 ( 19%)], train_loss: 0.08287\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.08081\n",
            "epoch: 005 [ 444/2267 ( 20%)], train_loss: 0.08322\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.08178\n",
            "epoch: 005 [ 468/2267 ( 21%)], train_loss: 0.08303\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.06569\n",
            "epoch: 005 [ 492/2267 ( 22%)], train_loss: 0.08298\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04167\n",
            "epoch: 005 [ 516/2267 ( 23%)], train_loss: 0.08390\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02134\n",
            "epoch: 005 [ 540/2267 ( 24%)], train_loss: 0.08501\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01487\n",
            "epoch: 005 [ 564/2267 ( 25%)], train_loss: 0.08533\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01830\n",
            "epoch: 005 [ 588/2267 ( 26%)], train_loss: 0.08543\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02845\n",
            "epoch: 005 [ 612/2267 ( 27%)], train_loss: 0.08624\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02321\n",
            "epoch: 005 [ 636/2267 ( 28%)], train_loss: 0.08585\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01522\n",
            "epoch: 005 [ 660/2267 ( 29%)], train_loss: 0.08531\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02225\n",
            "epoch: 005 [ 684/2267 ( 30%)], train_loss: 0.08504\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04128\n",
            "epoch: 005 [ 708/2267 ( 31%)], train_loss: 0.08537\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03939\n",
            "epoch: 005 [ 732/2267 ( 32%)], train_loss: 0.08491\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02632\n",
            "epoch: 005 [ 756/2267 ( 33%)], train_loss: 0.08536\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01540\n",
            "epoch: 005 [ 780/2267 ( 34%)], train_loss: 0.08550\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02004\n",
            "epoch: 005 [ 804/2267 ( 35%)], train_loss: 0.08547\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02825\n",
            "epoch: 005 [ 828/2267 ( 37%)], train_loss: 0.08501\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04547\n",
            "epoch: 005 [ 852/2267 ( 38%)], train_loss: 0.08518\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04514\n",
            "epoch: 005 [ 876/2267 ( 39%)], train_loss: 0.08500\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03187\n",
            "epoch: 005 [ 900/2267 ( 40%)], train_loss: 0.08429\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01651\n",
            "epoch: 005 [ 924/2267 ( 41%)], train_loss: 0.08443\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01525\n",
            "epoch: 005 [ 948/2267 ( 42%)], train_loss: 0.08463\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02274\n",
            "epoch: 005 [ 972/2267 ( 43%)], train_loss: 0.08469\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03887\n",
            "epoch: 005 [ 996/2267 ( 44%)], train_loss: 0.08448\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03489\n",
            "epoch: 005 [1020/2267 ( 45%)], train_loss: 0.08450\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03726\n",
            "epoch: 005 [1044/2267 ( 46%)], train_loss: 0.08450\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03601\n",
            "epoch: 005 [1068/2267 ( 47%)], train_loss: 0.08458\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02412\n",
            "epoch: 005 [1092/2267 ( 48%)], train_loss: 0.08492\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01566\n",
            "epoch: 005 [1116/2267 ( 49%)], train_loss: 0.08527\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01496\n",
            "epoch: 005 [1140/2267 ( 50%)], train_loss: 0.08524\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02284\n",
            "epoch: 005 [1164/2267 ( 51%)], train_loss: 0.08536\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02215\n",
            "epoch: 005 [1188/2267 ( 52%)], train_loss: 0.08515\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02453\n",
            "epoch: 005 [1212/2267 ( 53%)], train_loss: 0.08506\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02720\n",
            "epoch: 005 [1236/2267 ( 55%)], train_loss: 0.08531\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02127\n",
            "epoch: 005 [1260/2267 ( 56%)], train_loss: 0.08520\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02194\n",
            "epoch: 005 [1284/2267 ( 57%)], train_loss: 0.08558\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01818\n",
            "epoch: 005 [1308/2267 ( 58%)], train_loss: 0.08546\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01532\n",
            "epoch: 005 [1332/2267 ( 59%)], train_loss: 0.08545\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01528\n",
            "epoch: 005 [1356/2267 ( 60%)], train_loss: 0.08514\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01489\n",
            "epoch: 005 [1380/2267 ( 61%)], train_loss: 0.08531\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01771\n",
            "epoch: 005 [1404/2267 ( 62%)], train_loss: 0.08519\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01837\n",
            "epoch: 005 [1428/2267 ( 63%)], train_loss: 0.08562\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01542\n",
            "epoch: 005 [1452/2267 ( 64%)], train_loss: 0.08561\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01596\n",
            "epoch: 005 [1476/2267 ( 65%)], train_loss: 0.08563\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03598\n",
            "epoch: 005 [1500/2267 ( 66%)], train_loss: 0.08555\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.06490\n",
            "epoch: 005 [1524/2267 ( 67%)], train_loss: 0.08562\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.07253\n",
            "epoch: 005 [1548/2267 ( 68%)], train_loss: 0.08551\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.05802\n",
            "epoch: 005 [1572/2267 ( 69%)], train_loss: 0.08508\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04406\n",
            "epoch: 005 [1596/2267 ( 70%)], train_loss: 0.08492\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01948\n",
            "epoch: 005 [1620/2267 ( 71%)], train_loss: 0.08502\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01496\n",
            "epoch: 005 [1644/2267 ( 73%)], train_loss: 0.08509\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02034\n",
            "epoch: 005 [1668/2267 ( 74%)], train_loss: 0.08503\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03147\n",
            "epoch: 005 [1692/2267 ( 75%)], train_loss: 0.08510\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.02663\n",
            "epoch: 005 [1716/2267 ( 76%)], train_loss: 0.08489\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01829\n",
            "epoch: 005 [1740/2267 ( 77%)], train_loss: 0.08483\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01589\n",
            "epoch: 005 [1764/2267 ( 78%)], train_loss: 0.08454\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01492\n",
            "epoch: 005 [1788/2267 ( 79%)], train_loss: 0.08467\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01487\n",
            "epoch: 005 [1812/2267 ( 80%)], train_loss: 0.08463\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01530\n",
            "epoch: 005 [1836/2267 ( 81%)], train_loss: 0.08485\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01497\n",
            "epoch: 005 [1860/2267 ( 82%)], train_loss: 0.08487\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01528\n",
            "epoch: 005 [1884/2267 ( 83%)], train_loss: 0.08490\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03058\n",
            "epoch: 005 [1908/2267 ( 84%)], train_loss: 0.08493\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.06545\n",
            "epoch: 005 [1932/2267 ( 85%)], train_loss: 0.08508\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.07422\n",
            "epoch: 005 [1956/2267 ( 86%)], train_loss: 0.08514\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04985\n",
            "epoch: 005 [1980/2267 ( 87%)], train_loss: 0.08524\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01855\n",
            "epoch: 005 [2004/2267 ( 88%)], train_loss: 0.08546\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01518\n",
            "epoch: 005 [2028/2267 ( 89%)], train_loss: 0.08560\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01719\n",
            "epoch: 005 [2052/2267 ( 91%)], train_loss: 0.08566\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01555\n",
            "epoch: 005 [2076/2267 ( 92%)], train_loss: 0.08552\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01510\n",
            "epoch: 005 [2100/2267 ( 93%)], train_loss: 0.08564\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01554\n",
            "epoch: 005 [2124/2267 ( 94%)], train_loss: 0.08562\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01519\n",
            "epoch: 005 [2148/2267 ( 95%)], train_loss: 0.08562\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01488\n",
            "epoch: 005 [2172/2267 ( 96%)], train_loss: 0.08547\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.01966\n",
            "epoch: 005 [2196/2267 ( 97%)], train_loss: 0.08542\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03046\n",
            "epoch: 005 [2220/2267 ( 98%)], train_loss: 0.08547\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04285\n",
            "epoch: 005 [2244/2267 ( 99%)], train_loss: 0.08554\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.04348\n",
            "epoch: 005 [2267/2267 (100%)], train_loss: 0.08541\n",
            "----Validation Results Summary----\n",
            "Epoch: [5] train_loss: 1.03168\n",
            "epoch: 006 [  12/2267 (  1%)], train_loss: 0.09862\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02705\n",
            "epoch: 006 [  36/2267 (  2%)], train_loss: 0.09451\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01841\n",
            "epoch: 006 [  60/2267 (  3%)], train_loss: 0.08573\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01488\n",
            "epoch: 006 [  84/2267 (  4%)], train_loss: 0.08696\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01780\n",
            "epoch: 006 [ 108/2267 (  5%)], train_loss: 0.08456\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02118\n",
            "epoch: 006 [ 132/2267 (  6%)], train_loss: 0.08214\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02194\n",
            "epoch: 006 [ 156/2267 (  7%)], train_loss: 0.08037\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02071\n",
            "epoch: 006 [ 180/2267 (  8%)], train_loss: 0.08000\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01943\n",
            "epoch: 006 [ 204/2267 (  9%)], train_loss: 0.08022\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01836\n",
            "epoch: 006 [ 228/2267 ( 10%)], train_loss: 0.08165\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02046\n",
            "epoch: 006 [ 252/2267 ( 11%)], train_loss: 0.08311\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02274\n",
            "epoch: 006 [ 276/2267 ( 12%)], train_loss: 0.08206\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02053\n",
            "epoch: 006 [ 300/2267 ( 13%)], train_loss: 0.08171\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01731\n",
            "epoch: 006 [ 324/2267 ( 14%)], train_loss: 0.08194\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01489\n",
            "epoch: 006 [ 348/2267 ( 15%)], train_loss: 0.08238\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01671\n",
            "epoch: 006 [ 372/2267 ( 16%)], train_loss: 0.08326\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01873\n",
            "epoch: 006 [ 396/2267 ( 17%)], train_loss: 0.08249\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01858\n",
            "epoch: 006 [ 420/2267 ( 19%)], train_loss: 0.08245\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01984\n",
            "epoch: 006 [ 444/2267 ( 20%)], train_loss: 0.08249\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01999\n",
            "epoch: 006 [ 468/2267 ( 21%)], train_loss: 0.08361\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01740\n",
            "epoch: 006 [ 492/2267 ( 22%)], train_loss: 0.08343\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01608\n",
            "epoch: 006 [ 516/2267 ( 23%)], train_loss: 0.08306\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01490\n",
            "epoch: 006 [ 540/2267 ( 24%)], train_loss: 0.08199\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01689\n",
            "epoch: 006 [ 564/2267 ( 25%)], train_loss: 0.08161\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02147\n",
            "epoch: 006 [ 588/2267 ( 26%)], train_loss: 0.08183\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.03101\n",
            "epoch: 006 [ 612/2267 ( 27%)], train_loss: 0.08202\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.03528\n",
            "epoch: 006 [ 636/2267 ( 28%)], train_loss: 0.08126\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.03239\n",
            "epoch: 006 [ 660/2267 ( 29%)], train_loss: 0.08118\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02559\n",
            "epoch: 006 [ 684/2267 ( 30%)], train_loss: 0.08146\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01842\n",
            "epoch: 006 [ 708/2267 ( 31%)], train_loss: 0.08158\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01673\n",
            "epoch: 006 [ 732/2267 ( 32%)], train_loss: 0.08225\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01743\n",
            "epoch: 006 [ 756/2267 ( 33%)], train_loss: 0.08253\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01823\n",
            "epoch: 006 [ 780/2267 ( 34%)], train_loss: 0.08254\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01867\n",
            "epoch: 006 [ 804/2267 ( 35%)], train_loss: 0.08211\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02119\n",
            "epoch: 006 [ 828/2267 ( 37%)], train_loss: 0.08207\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01992\n",
            "epoch: 006 [ 852/2267 ( 38%)], train_loss: 0.08240\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02236\n",
            "epoch: 006 [ 876/2267 ( 39%)], train_loss: 0.08270\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02619\n",
            "epoch: 006 [ 900/2267 ( 40%)], train_loss: 0.08309\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02162\n",
            "epoch: 006 [ 924/2267 ( 41%)], train_loss: 0.08331\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01915\n",
            "epoch: 006 [ 948/2267 ( 42%)], train_loss: 0.08322\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01880\n",
            "epoch: 006 [ 972/2267 ( 43%)], train_loss: 0.08360\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01749\n",
            "epoch: 006 [ 996/2267 ( 44%)], train_loss: 0.08372\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01631\n",
            "epoch: 006 [1020/2267 ( 45%)], train_loss: 0.08342\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01556\n",
            "epoch: 006 [1044/2267 ( 46%)], train_loss: 0.08342\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01528\n",
            "epoch: 006 [1068/2267 ( 47%)], train_loss: 0.08308\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01487\n",
            "epoch: 006 [1092/2267 ( 48%)], train_loss: 0.08305\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01488\n",
            "epoch: 006 [1116/2267 ( 49%)], train_loss: 0.08304\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01501\n",
            "epoch: 006 [1140/2267 ( 50%)], train_loss: 0.08330\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01535\n",
            "epoch: 006 [1164/2267 ( 51%)], train_loss: 0.08360\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01558\n",
            "epoch: 006 [1188/2267 ( 52%)], train_loss: 0.08385\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01578\n",
            "epoch: 006 [1212/2267 ( 53%)], train_loss: 0.08398\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01531\n",
            "epoch: 006 [1236/2267 ( 55%)], train_loss: 0.08345\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01487\n",
            "epoch: 006 [1260/2267 ( 56%)], train_loss: 0.08334\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01512\n",
            "epoch: 006 [1284/2267 ( 57%)], train_loss: 0.08339\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01673\n",
            "epoch: 006 [1308/2267 ( 58%)], train_loss: 0.08314\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01824\n",
            "epoch: 006 [1332/2267 ( 59%)], train_loss: 0.08346\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01888\n",
            "epoch: 006 [1356/2267 ( 60%)], train_loss: 0.08341\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01783\n",
            "epoch: 006 [1380/2267 ( 61%)], train_loss: 0.08328\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01780\n",
            "epoch: 006 [1404/2267 ( 62%)], train_loss: 0.08324\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02017\n",
            "epoch: 006 [1428/2267 ( 63%)], train_loss: 0.08318\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02237\n",
            "epoch: 006 [1452/2267 ( 64%)], train_loss: 0.08323\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02200\n",
            "epoch: 006 [1476/2267 ( 65%)], train_loss: 0.08335\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02264\n",
            "epoch: 006 [1500/2267 ( 66%)], train_loss: 0.08352\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01744\n",
            "epoch: 006 [1524/2267 ( 67%)], train_loss: 0.08353\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01509\n",
            "epoch: 006 [1548/2267 ( 68%)], train_loss: 0.08338\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01494\n",
            "epoch: 006 [1572/2267 ( 69%)], train_loss: 0.08380\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01720\n",
            "epoch: 006 [1596/2267 ( 70%)], train_loss: 0.08374\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02272\n",
            "epoch: 006 [1620/2267 ( 71%)], train_loss: 0.08399\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02977\n",
            "epoch: 006 [1644/2267 ( 73%)], train_loss: 0.08415\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.03024\n",
            "epoch: 006 [1668/2267 ( 74%)], train_loss: 0.08416\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02984\n",
            "epoch: 006 [1692/2267 ( 75%)], train_loss: 0.08415\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02499\n",
            "epoch: 006 [1716/2267 ( 76%)], train_loss: 0.08409\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01976\n",
            "epoch: 006 [1740/2267 ( 77%)], train_loss: 0.08408\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01753\n",
            "epoch: 006 [1764/2267 ( 78%)], train_loss: 0.08429\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01578\n",
            "epoch: 006 [1788/2267 ( 79%)], train_loss: 0.08421\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01498\n",
            "epoch: 006 [1812/2267 ( 80%)], train_loss: 0.08436\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01552\n",
            "epoch: 006 [1836/2267 ( 81%)], train_loss: 0.08460\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01657\n",
            "epoch: 006 [1860/2267 ( 82%)], train_loss: 0.08459\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01975\n",
            "epoch: 006 [1884/2267 ( 83%)], train_loss: 0.08463\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02449\n",
            "epoch: 006 [1908/2267 ( 84%)], train_loss: 0.08464\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02737\n",
            "epoch: 006 [1932/2267 ( 85%)], train_loss: 0.08470\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02892\n",
            "epoch: 006 [1956/2267 ( 86%)], train_loss: 0.08477\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02634\n",
            "epoch: 006 [1980/2267 ( 87%)], train_loss: 0.08475\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02185\n",
            "epoch: 006 [2004/2267 ( 88%)], train_loss: 0.08482\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01936\n",
            "epoch: 006 [2028/2267 ( 89%)], train_loss: 0.08472\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01782\n",
            "epoch: 006 [2052/2267 ( 91%)], train_loss: 0.08473\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01986\n",
            "epoch: 006 [2076/2267 ( 92%)], train_loss: 0.08495\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02443\n",
            "epoch: 006 [2100/2267 ( 93%)], train_loss: 0.08485\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02435\n",
            "epoch: 006 [2124/2267 ( 94%)], train_loss: 0.08482\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02298\n",
            "epoch: 006 [2148/2267 ( 95%)], train_loss: 0.08485\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.02039\n",
            "epoch: 006 [2172/2267 ( 96%)], train_loss: 0.08490\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01948\n",
            "epoch: 006 [2196/2267 ( 97%)], train_loss: 0.08485\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01835\n",
            "epoch: 006 [2220/2267 ( 98%)], train_loss: 0.08466\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01632\n",
            "epoch: 006 [2244/2267 ( 99%)], train_loss: 0.08466\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01496\n",
            "epoch: 006 [2267/2267 (100%)], train_loss: 0.08469\n",
            "----Validation Results Summary----\n",
            "Epoch: [6] train_loss: 1.01767\n",
            "epoch: 007 [  12/2267 (  1%)], train_loss: 0.09234\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01808\n",
            "epoch: 007 [  36/2267 (  2%)], train_loss: 0.07275\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01831\n",
            "epoch: 007 [  60/2267 (  3%)], train_loss: 0.07319\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01780\n",
            "epoch: 007 [  84/2267 (  4%)], train_loss: 0.07520\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01678\n",
            "epoch: 007 [ 108/2267 (  5%)], train_loss: 0.07380\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01599\n",
            "epoch: 007 [ 132/2267 (  6%)], train_loss: 0.08002\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01543\n",
            "epoch: 007 [ 156/2267 (  7%)], train_loss: 0.08018\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01505\n",
            "epoch: 007 [ 180/2267 (  8%)], train_loss: 0.08103\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01488\n",
            "epoch: 007 [ 204/2267 (  9%)], train_loss: 0.08220\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01491\n",
            "epoch: 007 [ 228/2267 ( 10%)], train_loss: 0.08239\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01508\n",
            "epoch: 007 [ 252/2267 ( 11%)], train_loss: 0.08448\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01531\n",
            "epoch: 007 [ 276/2267 ( 12%)], train_loss: 0.08345\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01527\n",
            "epoch: 007 [ 300/2267 ( 13%)], train_loss: 0.08309\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01518\n",
            "epoch: 007 [ 324/2267 ( 14%)], train_loss: 0.08446\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01506\n",
            "epoch: 007 [ 348/2267 ( 15%)], train_loss: 0.08424\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01501\n",
            "epoch: 007 [ 372/2267 ( 16%)], train_loss: 0.08397\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01513\n",
            "epoch: 007 [ 396/2267 ( 17%)], train_loss: 0.08329\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01517\n",
            "epoch: 007 [ 420/2267 ( 19%)], train_loss: 0.08264\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01503\n",
            "epoch: 007 [ 444/2267 ( 20%)], train_loss: 0.08308\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01508\n",
            "epoch: 007 [ 468/2267 ( 21%)], train_loss: 0.08410\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01548\n",
            "epoch: 007 [ 492/2267 ( 22%)], train_loss: 0.08361\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01632\n",
            "epoch: 007 [ 516/2267 ( 23%)], train_loss: 0.08371\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01737\n",
            "epoch: 007 [ 540/2267 ( 24%)], train_loss: 0.08364\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01889\n",
            "epoch: 007 [ 564/2267 ( 25%)], train_loss: 0.08351\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01979\n",
            "epoch: 007 [ 588/2267 ( 26%)], train_loss: 0.08359\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.02025\n",
            "epoch: 007 [ 612/2267 ( 27%)], train_loss: 0.08336\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.02024\n",
            "epoch: 007 [ 636/2267 ( 28%)], train_loss: 0.08307\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01996\n",
            "epoch: 007 [ 660/2267 ( 29%)], train_loss: 0.08281\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01901\n",
            "epoch: 007 [ 684/2267 ( 30%)], train_loss: 0.08345\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01804\n",
            "epoch: 007 [ 708/2267 ( 31%)], train_loss: 0.08333\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01678\n",
            "epoch: 007 [ 732/2267 ( 32%)], train_loss: 0.08301\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01611\n",
            "epoch: 007 [ 756/2267 ( 33%)], train_loss: 0.08308\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01569\n",
            "epoch: 007 [ 780/2267 ( 34%)], train_loss: 0.08229\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01535\n",
            "epoch: 007 [ 804/2267 ( 35%)], train_loss: 0.08255\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01509\n",
            "epoch: 007 [ 828/2267 ( 37%)], train_loss: 0.08228\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01504\n",
            "epoch: 007 [ 852/2267 ( 38%)], train_loss: 0.08211\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01496\n",
            "epoch: 007 [ 876/2267 ( 39%)], train_loss: 0.08189\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01487\n",
            "epoch: 007 [ 900/2267 ( 40%)], train_loss: 0.08192\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01506\n",
            "epoch: 007 [ 924/2267 ( 41%)], train_loss: 0.08224\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01559\n",
            "epoch: 007 [ 948/2267 ( 42%)], train_loss: 0.08203\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01631\n",
            "epoch: 007 [ 972/2267 ( 43%)], train_loss: 0.08184\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01681\n",
            "epoch: 007 [ 996/2267 ( 44%)], train_loss: 0.08202\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01717\n",
            "epoch: 007 [1020/2267 ( 45%)], train_loss: 0.08219\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01710\n",
            "epoch: 007 [1044/2267 ( 46%)], train_loss: 0.08247\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01644\n",
            "epoch: 007 [1068/2267 ( 47%)], train_loss: 0.08241\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01632\n",
            "epoch: 007 [1092/2267 ( 48%)], train_loss: 0.08228\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01624\n",
            "epoch: 007 [1116/2267 ( 49%)], train_loss: 0.08218\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01596\n",
            "epoch: 007 [1140/2267 ( 50%)], train_loss: 0.08220\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01543\n",
            "epoch: 007 [1164/2267 ( 51%)], train_loss: 0.08237\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01502\n",
            "epoch: 007 [1188/2267 ( 52%)], train_loss: 0.08226\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01489\n",
            "epoch: 007 [1212/2267 ( 53%)], train_loss: 0.08233\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01487\n",
            "epoch: 007 [1236/2267 ( 55%)], train_loss: 0.08276\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01493\n",
            "epoch: 007 [1260/2267 ( 56%)], train_loss: 0.08297\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01530\n",
            "epoch: 007 [1284/2267 ( 57%)], train_loss: 0.08309\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01571\n",
            "epoch: 007 [1308/2267 ( 58%)], train_loss: 0.08311\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01616\n",
            "epoch: 007 [1332/2267 ( 59%)], train_loss: 0.08287\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01691\n",
            "epoch: 007 [1356/2267 ( 60%)], train_loss: 0.08271\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01734\n",
            "epoch: 007 [1380/2267 ( 61%)], train_loss: 0.08255\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01776\n",
            "epoch: 007 [1404/2267 ( 62%)], train_loss: 0.08242\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01814\n",
            "epoch: 007 [1428/2267 ( 63%)], train_loss: 0.08230\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01858\n",
            "epoch: 007 [1452/2267 ( 64%)], train_loss: 0.08228\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01865\n",
            "epoch: 007 [1476/2267 ( 65%)], train_loss: 0.08251\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01785\n",
            "epoch: 007 [1500/2267 ( 66%)], train_loss: 0.08274\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01731\n",
            "epoch: 007 [1524/2267 ( 67%)], train_loss: 0.08292\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01678\n",
            "epoch: 007 [1548/2267 ( 68%)], train_loss: 0.08318\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01709\n",
            "epoch: 007 [1572/2267 ( 69%)], train_loss: 0.08315\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01739\n",
            "epoch: 007 [1596/2267 ( 70%)], train_loss: 0.08305\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01723\n",
            "epoch: 007 [1620/2267 ( 71%)], train_loss: 0.08302\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01773\n",
            "epoch: 007 [1644/2267 ( 73%)], train_loss: 0.08302\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01780\n",
            "epoch: 007 [1668/2267 ( 74%)], train_loss: 0.08286\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01746\n",
            "epoch: 007 [1692/2267 ( 75%)], train_loss: 0.08280\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01717\n",
            "epoch: 007 [1716/2267 ( 76%)], train_loss: 0.08285\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01695\n",
            "epoch: 007 [1740/2267 ( 77%)], train_loss: 0.08275\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01697\n",
            "epoch: 007 [1764/2267 ( 78%)], train_loss: 0.08285\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01679\n",
            "epoch: 007 [1788/2267 ( 79%)], train_loss: 0.08287\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01662\n",
            "epoch: 007 [1812/2267 ( 80%)], train_loss: 0.08316\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01649\n",
            "epoch: 007 [1836/2267 ( 81%)], train_loss: 0.08315\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01648\n",
            "epoch: 007 [1860/2267 ( 82%)], train_loss: 0.08331\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01667\n",
            "epoch: 007 [1884/2267 ( 83%)], train_loss: 0.08325\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01687\n",
            "epoch: 007 [1908/2267 ( 84%)], train_loss: 0.08340\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01659\n",
            "epoch: 007 [1932/2267 ( 85%)], train_loss: 0.08353\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01679\n",
            "epoch: 007 [1956/2267 ( 86%)], train_loss: 0.08362\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01839\n",
            "epoch: 007 [1980/2267 ( 87%)], train_loss: 0.08347\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01994\n",
            "epoch: 007 [2004/2267 ( 88%)], train_loss: 0.08343\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.02012\n",
            "epoch: 007 [2028/2267 ( 89%)], train_loss: 0.08351\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01940\n",
            "epoch: 007 [2052/2267 ( 91%)], train_loss: 0.08363\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01915\n",
            "epoch: 007 [2076/2267 ( 92%)], train_loss: 0.08377\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01861\n",
            "epoch: 007 [2100/2267 ( 93%)], train_loss: 0.08381\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01813\n",
            "epoch: 007 [2124/2267 ( 94%)], train_loss: 0.08391\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01821\n",
            "epoch: 007 [2148/2267 ( 95%)], train_loss: 0.08394\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01821\n",
            "epoch: 007 [2172/2267 ( 96%)], train_loss: 0.08424\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01875\n",
            "epoch: 007 [2196/2267 ( 97%)], train_loss: 0.08440\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01928\n",
            "epoch: 007 [2220/2267 ( 98%)], train_loss: 0.08437\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01993\n",
            "epoch: 007 [2244/2267 ( 99%)], train_loss: 0.08425\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01981\n",
            "epoch: 007 [2267/2267 (100%)], train_loss: 0.08433\n",
            "----Validation Results Summary----\n",
            "Epoch: [7] train_loss: 1.01890\n",
            "----\n",
            "\n",
            "----\n",
            "FOLD: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/kaggle/readability/robertalarge-e1 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/kaggle/readability/robertalarge-e1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n",
            "epoch: 000 [  12/2267 (  1%)], train_loss: 0.15347\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.05275\n",
            "0 epoch, best epoch was updated! valid_loss: 1.05275\n",
            "epoch: 000 [  36/2267 (  2%)], train_loss: 0.10428\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.92598\n",
            "0 epoch, best epoch was updated! valid_loss: 0.92598\n",
            "epoch: 000 [  60/2267 (  3%)], train_loss: 0.09847\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.87158\n",
            "0 epoch, best epoch was updated! valid_loss: 0.87158\n",
            "epoch: 000 [  84/2267 (  4%)], train_loss: 0.09187\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.79634\n",
            "0 epoch, best epoch was updated! valid_loss: 0.79634\n",
            "epoch: 000 [ 108/2267 (  5%)], train_loss: 0.08870\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.79499\n",
            "0 epoch, best epoch was updated! valid_loss: 0.79499\n",
            "epoch: 000 [ 132/2267 (  6%)], train_loss: 0.08270\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 1.47171\n",
            "epoch: 000 [ 156/2267 (  7%)], train_loss: 0.08338\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.76518\n",
            "0 epoch, best epoch was updated! valid_loss: 0.76518\n",
            "epoch: 000 [ 180/2267 (  8%)], train_loss: 0.08137\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.79077\n",
            "epoch: 000 [ 204/2267 (  9%)], train_loss: 0.08295\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.75702\n",
            "0 epoch, best epoch was updated! valid_loss: 0.75702\n",
            "epoch: 000 [ 228/2267 ( 10%)], train_loss: 0.08038\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.90372\n",
            "epoch: 000 [ 252/2267 ( 11%)], train_loss: 0.08190\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.66909\n",
            "0 epoch, best epoch was updated! valid_loss: 0.66909\n",
            "epoch: 000 [ 276/2267 ( 12%)], train_loss: 0.08093\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.66781\n",
            "0 epoch, best epoch was updated! valid_loss: 0.66781\n",
            "epoch: 000 [ 300/2267 ( 13%)], train_loss: 0.08017\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68326\n",
            "epoch: 000 [ 324/2267 ( 14%)], train_loss: 0.08022\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.85245\n",
            "epoch: 000 [ 348/2267 ( 15%)], train_loss: 0.07921\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.67507\n",
            "epoch: 000 [ 372/2267 ( 16%)], train_loss: 0.07900\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.83139\n",
            "epoch: 000 [ 396/2267 ( 17%)], train_loss: 0.07749\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.86552\n",
            "epoch: 000 [ 420/2267 ( 19%)], train_loss: 0.07798\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.92643\n",
            "epoch: 000 [ 444/2267 ( 20%)], train_loss: 0.07776\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78169\n",
            "epoch: 000 [ 468/2267 ( 21%)], train_loss: 0.07763\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.92897\n",
            "epoch: 000 [ 492/2267 ( 22%)], train_loss: 0.07756\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.87038\n",
            "epoch: 000 [ 516/2267 ( 23%)], train_loss: 0.07667\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.78379\n",
            "epoch: 000 [ 540/2267 ( 24%)], train_loss: 0.07650\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.94967\n",
            "epoch: 000 [ 564/2267 ( 25%)], train_loss: 0.07641\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.85922\n",
            "epoch: 000 [ 588/2267 ( 26%)], train_loss: 0.07541\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72913\n",
            "epoch: 000 [ 612/2267 ( 27%)], train_loss: 0.07470\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.71881\n",
            "epoch: 000 [ 636/2267 ( 28%)], train_loss: 0.07463\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.67520\n",
            "epoch: 000 [ 660/2267 ( 29%)], train_loss: 0.07381\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63653\n",
            "0 epoch, best epoch was updated! valid_loss: 0.63653\n",
            "epoch: 000 [ 684/2267 ( 30%)], train_loss: 0.07328\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63407\n",
            "0 epoch, best epoch was updated! valid_loss: 0.63407\n",
            "epoch: 000 [ 708/2267 ( 31%)], train_loss: 0.07245\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.70909\n",
            "epoch: 000 [ 732/2267 ( 32%)], train_loss: 0.07207\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69107\n",
            "epoch: 000 [ 756/2267 ( 33%)], train_loss: 0.07190\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.80571\n",
            "epoch: 000 [ 780/2267 ( 34%)], train_loss: 0.07152\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.59968\n",
            "0 epoch, best epoch was updated! valid_loss: 0.59968\n",
            "epoch: 000 [ 804/2267 ( 35%)], train_loss: 0.07103\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.70501\n",
            "epoch: 000 [ 828/2267 ( 37%)], train_loss: 0.07123\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.65322\n",
            "epoch: 000 [ 852/2267 ( 38%)], train_loss: 0.07083\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68336\n",
            "epoch: 000 [ 876/2267 ( 39%)], train_loss: 0.07029\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63889\n",
            "epoch: 000 [ 900/2267 ( 40%)], train_loss: 0.06980\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64249\n",
            "epoch: 000 [ 924/2267 ( 41%)], train_loss: 0.06998\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.72025\n",
            "epoch: 000 [ 948/2267 ( 42%)], train_loss: 0.06972\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64863\n",
            "epoch: 000 [ 972/2267 ( 43%)], train_loss: 0.06956\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.66062\n",
            "epoch: 000 [ 996/2267 ( 44%)], train_loss: 0.06926\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69194\n",
            "epoch: 000 [1020/2267 ( 45%)], train_loss: 0.06905\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64479\n",
            "epoch: 000 [1044/2267 ( 46%)], train_loss: 0.06887\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.65953\n",
            "epoch: 000 [1068/2267 ( 47%)], train_loss: 0.06857\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64586\n",
            "epoch: 000 [1092/2267 ( 48%)], train_loss: 0.06825\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.61368\n",
            "epoch: 000 [1116/2267 ( 49%)], train_loss: 0.06801\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.59685\n",
            "0 epoch, best epoch was updated! valid_loss: 0.59685\n",
            "epoch: 000 [1140/2267 ( 50%)], train_loss: 0.06757\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68562\n",
            "epoch: 000 [1164/2267 ( 51%)], train_loss: 0.06748\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.86369\n",
            "epoch: 000 [1188/2267 ( 52%)], train_loss: 0.06753\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.80794\n",
            "epoch: 000 [1212/2267 ( 53%)], train_loss: 0.06762\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.67506\n",
            "epoch: 000 [1236/2267 ( 55%)], train_loss: 0.06739\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.81586\n",
            "epoch: 000 [1260/2267 ( 56%)], train_loss: 0.06765\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73735\n",
            "epoch: 000 [1284/2267 ( 57%)], train_loss: 0.06743\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69373\n",
            "epoch: 000 [1308/2267 ( 58%)], train_loss: 0.06748\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68974\n",
            "epoch: 000 [1332/2267 ( 59%)], train_loss: 0.06720\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.60183\n",
            "epoch: 000 [1356/2267 ( 60%)], train_loss: 0.06690\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68409\n",
            "epoch: 000 [1380/2267 ( 61%)], train_loss: 0.06684\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.70453\n",
            "epoch: 000 [1404/2267 ( 62%)], train_loss: 0.06677\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.68845\n",
            "epoch: 000 [1428/2267 ( 63%)], train_loss: 0.06710\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.77777\n",
            "epoch: 000 [1452/2267 ( 64%)], train_loss: 0.06716\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.71424\n",
            "epoch: 000 [1476/2267 ( 65%)], train_loss: 0.06722\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69238\n",
            "epoch: 000 [1500/2267 ( 66%)], train_loss: 0.06718\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.76526\n",
            "epoch: 000 [1524/2267 ( 67%)], train_loss: 0.06707\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.58947\n",
            "0 epoch, best epoch was updated! valid_loss: 0.58947\n",
            "epoch: 000 [1548/2267 ( 68%)], train_loss: 0.06668\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69036\n",
            "epoch: 000 [1572/2267 ( 69%)], train_loss: 0.06654\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.57688\n",
            "0 epoch, best epoch was updated! valid_loss: 0.57688\n",
            "epoch: 000 [1596/2267 ( 70%)], train_loss: 0.06632\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.60849\n",
            "epoch: 000 [1620/2267 ( 71%)], train_loss: 0.06593\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.54273\n",
            "0 epoch, best epoch was updated! valid_loss: 0.54273\n",
            "epoch: 000 [1644/2267 ( 73%)], train_loss: 0.06552\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.53986\n",
            "0 epoch, best epoch was updated! valid_loss: 0.53986\n",
            "epoch: 000 [1668/2267 ( 74%)], train_loss: 0.06538\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.55908\n",
            "epoch: 000 [1692/2267 ( 75%)], train_loss: 0.06520\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.55676\n",
            "epoch: 000 [1716/2267 ( 76%)], train_loss: 0.06498\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.55206\n",
            "epoch: 000 [1740/2267 ( 77%)], train_loss: 0.06474\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.62387\n",
            "epoch: 000 [1764/2267 ( 78%)], train_loss: 0.06443\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.58282\n",
            "epoch: 000 [1788/2267 ( 79%)], train_loss: 0.06434\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.67531\n",
            "epoch: 000 [1812/2267 ( 80%)], train_loss: 0.06413\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.63406\n",
            "epoch: 000 [1836/2267 ( 81%)], train_loss: 0.06403\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.64350\n",
            "epoch: 000 [1860/2267 ( 82%)], train_loss: 0.06379\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.62516\n",
            "epoch: 000 [1884/2267 ( 83%)], train_loss: 0.06352\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73133\n",
            "epoch: 000 [1908/2267 ( 84%)], train_loss: 0.06346\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.54863\n",
            "epoch: 000 [1932/2267 ( 85%)], train_loss: 0.06335\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.73149\n",
            "epoch: 000 [1956/2267 ( 86%)], train_loss: 0.06323\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.52398\n",
            "0 epoch, best epoch was updated! valid_loss: 0.52398\n",
            "epoch: 000 [1980/2267 ( 87%)], train_loss: 0.06311\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.93802\n",
            "epoch: 000 [2004/2267 ( 88%)], train_loss: 0.06322\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.59184\n",
            "epoch: 000 [2028/2267 ( 89%)], train_loss: 0.06312\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.74892\n",
            "epoch: 000 [2052/2267 ( 91%)], train_loss: 0.06322\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.58304\n",
            "epoch: 000 [2076/2267 ( 92%)], train_loss: 0.06318\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.69458\n",
            "epoch: 000 [2100/2267 ( 93%)], train_loss: 0.06313\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.71219\n",
            "epoch: 000 [2124/2267 ( 94%)], train_loss: 0.06302\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.65252\n",
            "epoch: 000 [2148/2267 ( 95%)], train_loss: 0.06305\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.66015\n",
            "epoch: 000 [2172/2267 ( 96%)], train_loss: 0.06296\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.52223\n",
            "0 epoch, best epoch was updated! valid_loss: 0.52223\n",
            "epoch: 000 [2196/2267 ( 97%)], train_loss: 0.06280\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.54422\n",
            "epoch: 000 [2220/2267 ( 98%)], train_loss: 0.06250\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.53933\n",
            "epoch: 000 [2244/2267 ( 99%)], train_loss: 0.06249\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.56149\n",
            "epoch: 000 [2267/2267 (100%)], train_loss: 0.06236\n",
            "----Validation Results Summary----\n",
            "Epoch: [0] train_loss: 0.52316\n",
            "epoch: 001 [  12/2267 (  1%)], train_loss: 0.09687\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.56537\n",
            "epoch: 001 [  36/2267 (  2%)], train_loss: 0.05598\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52511\n",
            "epoch: 001 [  60/2267 (  3%)], train_loss: 0.04854\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52417\n",
            "epoch: 001 [  84/2267 (  4%)], train_loss: 0.04607\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.56446\n",
            "epoch: 001 [ 108/2267 (  5%)], train_loss: 0.04540\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53017\n",
            "epoch: 001 [ 132/2267 (  6%)], train_loss: 0.04622\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53066\n",
            "epoch: 001 [ 156/2267 (  7%)], train_loss: 0.04572\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.71530\n",
            "epoch: 001 [ 180/2267 (  8%)], train_loss: 0.04700\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.65266\n",
            "epoch: 001 [ 204/2267 (  9%)], train_loss: 0.04638\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.60729\n",
            "epoch: 001 [ 228/2267 ( 10%)], train_loss: 0.04592\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55936\n",
            "epoch: 001 [ 252/2267 ( 11%)], train_loss: 0.04470\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52947\n",
            "epoch: 001 [ 276/2267 ( 12%)], train_loss: 0.04497\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55339\n",
            "epoch: 001 [ 300/2267 ( 13%)], train_loss: 0.04440\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.54961\n",
            "epoch: 001 [ 324/2267 ( 14%)], train_loss: 0.04480\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52951\n",
            "epoch: 001 [ 348/2267 ( 15%)], train_loss: 0.04444\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.65583\n",
            "epoch: 001 [ 372/2267 ( 16%)], train_loss: 0.04461\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52378\n",
            "epoch: 001 [ 396/2267 ( 17%)], train_loss: 0.04471\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.54539\n",
            "epoch: 001 [ 420/2267 ( 19%)], train_loss: 0.04446\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.56680\n",
            "epoch: 001 [ 444/2267 ( 20%)], train_loss: 0.04423\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.66541\n",
            "epoch: 001 [ 468/2267 ( 21%)], train_loss: 0.04432\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.66071\n",
            "epoch: 001 [ 492/2267 ( 22%)], train_loss: 0.04447\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.79745\n",
            "epoch: 001 [ 516/2267 ( 23%)], train_loss: 0.04512\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.57003\n",
            "epoch: 001 [ 540/2267 ( 24%)], train_loss: 0.04511\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.64062\n",
            "epoch: 001 [ 564/2267 ( 25%)], train_loss: 0.04527\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.50970\n",
            "1 epoch, best epoch was updated! valid_loss: 0.50970\n",
            "epoch: 001 [ 588/2267 ( 26%)], train_loss: 0.04505\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.49414\n",
            "1 epoch, best epoch was updated! valid_loss: 0.49414\n",
            "epoch: 001 [ 612/2267 ( 27%)], train_loss: 0.04487\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.50857\n",
            "epoch: 001 [ 636/2267 ( 28%)], train_loss: 0.04498\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.48987\n",
            "1 epoch, best epoch was updated! valid_loss: 0.48987\n",
            "epoch: 001 [ 660/2267 ( 29%)], train_loss: 0.04460\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.49683\n",
            "epoch: 001 [ 684/2267 ( 30%)], train_loss: 0.04409\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.49432\n",
            "epoch: 001 [ 708/2267 ( 31%)], train_loss: 0.04374\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.50552\n",
            "epoch: 001 [ 732/2267 ( 32%)], train_loss: 0.04353\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51524\n",
            "epoch: 001 [ 756/2267 ( 33%)], train_loss: 0.04345\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.50364\n",
            "epoch: 001 [ 780/2267 ( 34%)], train_loss: 0.04317\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.49566\n",
            "epoch: 001 [ 804/2267 ( 35%)], train_loss: 0.04310\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.48607\n",
            "1 epoch, best epoch was updated! valid_loss: 0.48607\n",
            "epoch: 001 [ 828/2267 ( 37%)], train_loss: 0.04307\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52710\n",
            "epoch: 001 [ 852/2267 ( 38%)], train_loss: 0.04297\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.61516\n",
            "epoch: 001 [ 876/2267 ( 39%)], train_loss: 0.04309\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51662\n",
            "epoch: 001 [ 900/2267 ( 40%)], train_loss: 0.04312\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55846\n",
            "epoch: 001 [ 924/2267 ( 41%)], train_loss: 0.04317\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52476\n",
            "epoch: 001 [ 948/2267 ( 42%)], train_loss: 0.04335\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59143\n",
            "epoch: 001 [ 972/2267 ( 43%)], train_loss: 0.04339\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53237\n",
            "epoch: 001 [ 996/2267 ( 44%)], train_loss: 0.04329\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59580\n",
            "epoch: 001 [1020/2267 ( 45%)], train_loss: 0.04327\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53889\n",
            "epoch: 001 [1044/2267 ( 46%)], train_loss: 0.04324\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.57034\n",
            "epoch: 001 [1068/2267 ( 47%)], train_loss: 0.04308\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.60644\n",
            "epoch: 001 [1092/2267 ( 48%)], train_loss: 0.04319\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53806\n",
            "epoch: 001 [1116/2267 ( 49%)], train_loss: 0.04294\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.71745\n",
            "epoch: 001 [1140/2267 ( 50%)], train_loss: 0.04320\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59989\n",
            "epoch: 001 [1164/2267 ( 51%)], train_loss: 0.04325\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.84007\n",
            "epoch: 001 [1188/2267 ( 52%)], train_loss: 0.04380\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.80010\n",
            "epoch: 001 [1212/2267 ( 53%)], train_loss: 0.04397\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.67834\n",
            "epoch: 001 [1236/2267 ( 55%)], train_loss: 0.04444\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.74208\n",
            "epoch: 001 [1260/2267 ( 56%)], train_loss: 0.04451\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.64444\n",
            "epoch: 001 [1284/2267 ( 57%)], train_loss: 0.04463\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.79307\n",
            "epoch: 001 [1308/2267 ( 58%)], train_loss: 0.04467\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.56682\n",
            "epoch: 001 [1332/2267 ( 59%)], train_loss: 0.04484\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.83462\n",
            "epoch: 001 [1356/2267 ( 60%)], train_loss: 0.04515\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59296\n",
            "epoch: 001 [1380/2267 ( 61%)], train_loss: 0.04493\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.57660\n",
            "epoch: 001 [1404/2267 ( 62%)], train_loss: 0.04475\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51188\n",
            "epoch: 001 [1428/2267 ( 63%)], train_loss: 0.04475\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.57607\n",
            "epoch: 001 [1452/2267 ( 64%)], train_loss: 0.04451\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52500\n",
            "epoch: 001 [1476/2267 ( 65%)], train_loss: 0.04451\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53928\n",
            "epoch: 001 [1500/2267 ( 66%)], train_loss: 0.04419\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51033\n",
            "epoch: 001 [1524/2267 ( 67%)], train_loss: 0.04409\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53124\n",
            "epoch: 001 [1548/2267 ( 68%)], train_loss: 0.04392\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.60837\n",
            "epoch: 001 [1572/2267 ( 69%)], train_loss: 0.04381\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.70069\n",
            "epoch: 001 [1596/2267 ( 70%)], train_loss: 0.04402\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55510\n",
            "epoch: 001 [1620/2267 ( 71%)], train_loss: 0.04391\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.63731\n",
            "epoch: 001 [1644/2267 ( 73%)], train_loss: 0.04387\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53016\n",
            "epoch: 001 [1668/2267 ( 74%)], train_loss: 0.04385\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59545\n",
            "epoch: 001 [1692/2267 ( 75%)], train_loss: 0.04376\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55315\n",
            "epoch: 001 [1716/2267 ( 76%)], train_loss: 0.04396\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51076\n",
            "epoch: 001 [1740/2267 ( 77%)], train_loss: 0.04385\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.63365\n",
            "epoch: 001 [1764/2267 ( 78%)], train_loss: 0.04373\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.49882\n",
            "epoch: 001 [1788/2267 ( 79%)], train_loss: 0.04351\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.58387\n",
            "epoch: 001 [1812/2267 ( 80%)], train_loss: 0.04357\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51982\n",
            "epoch: 001 [1836/2267 ( 81%)], train_loss: 0.04350\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.72668\n",
            "epoch: 001 [1860/2267 ( 82%)], train_loss: 0.04356\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51646\n",
            "epoch: 001 [1884/2267 ( 83%)], train_loss: 0.04351\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.70874\n",
            "epoch: 001 [1908/2267 ( 84%)], train_loss: 0.04360\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55172\n",
            "epoch: 001 [1932/2267 ( 85%)], train_loss: 0.04357\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.86157\n",
            "epoch: 001 [1956/2267 ( 86%)], train_loss: 0.04385\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.59376\n",
            "epoch: 001 [1980/2267 ( 87%)], train_loss: 0.04381\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.65705\n",
            "epoch: 001 [2004/2267 ( 88%)], train_loss: 0.04384\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.67385\n",
            "epoch: 001 [2028/2267 ( 89%)], train_loss: 0.04393\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.60926\n",
            "epoch: 001 [2052/2267 ( 91%)], train_loss: 0.04407\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.71597\n",
            "epoch: 001 [2076/2267 ( 92%)], train_loss: 0.04415\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.52113\n",
            "epoch: 001 [2100/2267 ( 93%)], train_loss: 0.04397\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.54122\n",
            "epoch: 001 [2124/2267 ( 94%)], train_loss: 0.04396\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.51594\n",
            "epoch: 001 [2148/2267 ( 95%)], train_loss: 0.04392\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.63929\n",
            "epoch: 001 [2172/2267 ( 96%)], train_loss: 0.04390\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55952\n",
            "epoch: 001 [2196/2267 ( 97%)], train_loss: 0.04383\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.63409\n",
            "epoch: 001 [2220/2267 ( 98%)], train_loss: 0.04392\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.55736\n",
            "epoch: 001 [2244/2267 ( 99%)], train_loss: 0.04381\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.53610\n",
            "epoch: 001 [2267/2267 (100%)], train_loss: 0.04378\n",
            "----Validation Results Summary----\n",
            "Epoch: [1] train_loss: 0.63253\n",
            "epoch: 002 [  12/2267 (  1%)], train_loss: 0.06572\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.56791\n",
            "epoch: 002 [  36/2267 (  2%)], train_loss: 0.04556\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53007\n",
            "epoch: 002 [  60/2267 (  3%)], train_loss: 0.03768\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.52833\n",
            "epoch: 002 [  84/2267 (  4%)], train_loss: 0.03329\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.56998\n",
            "epoch: 002 [ 108/2267 (  5%)], train_loss: 0.03337\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.57330\n",
            "epoch: 002 [ 132/2267 (  6%)], train_loss: 0.03230\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54129\n",
            "epoch: 002 [ 156/2267 (  7%)], train_loss: 0.03265\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.55165\n",
            "epoch: 002 [ 180/2267 (  8%)], train_loss: 0.03275\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.52511\n",
            "epoch: 002 [ 204/2267 (  9%)], train_loss: 0.03241\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50500\n",
            "epoch: 002 [ 228/2267 ( 10%)], train_loss: 0.03207\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.56084\n",
            "epoch: 002 [ 252/2267 ( 11%)], train_loss: 0.03180\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51640\n",
            "epoch: 002 [ 276/2267 ( 12%)], train_loss: 0.03187\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49112\n",
            "epoch: 002 [ 300/2267 ( 13%)], train_loss: 0.03176\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53139\n",
            "epoch: 002 [ 324/2267 ( 14%)], train_loss: 0.03167\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54649\n",
            "epoch: 002 [ 348/2267 ( 15%)], train_loss: 0.03163\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.62758\n",
            "epoch: 002 [ 372/2267 ( 16%)], train_loss: 0.03231\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.57365\n",
            "epoch: 002 [ 396/2267 ( 17%)], train_loss: 0.03300\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.72712\n",
            "epoch: 002 [ 420/2267 ( 19%)], train_loss: 0.03394\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51341\n",
            "epoch: 002 [ 444/2267 ( 20%)], train_loss: 0.03417\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.88261\n",
            "epoch: 002 [ 468/2267 ( 21%)], train_loss: 0.03521\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53060\n",
            "epoch: 002 [ 492/2267 ( 22%)], train_loss: 0.03569\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.65170\n",
            "epoch: 002 [ 516/2267 ( 23%)], train_loss: 0.03630\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51686\n",
            "epoch: 002 [ 540/2267 ( 24%)], train_loss: 0.03607\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.61786\n",
            "epoch: 002 [ 564/2267 ( 25%)], train_loss: 0.03559\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.52719\n",
            "epoch: 002 [ 588/2267 ( 26%)], train_loss: 0.03572\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53294\n",
            "epoch: 002 [ 612/2267 ( 27%)], train_loss: 0.03536\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50740\n",
            "epoch: 002 [ 636/2267 ( 28%)], train_loss: 0.03522\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50197\n",
            "epoch: 002 [ 660/2267 ( 29%)], train_loss: 0.03517\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50665\n",
            "epoch: 002 [ 684/2267 ( 30%)], train_loss: 0.03515\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50151\n",
            "epoch: 002 [ 708/2267 ( 31%)], train_loss: 0.03488\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.52210\n",
            "epoch: 002 [ 732/2267 ( 32%)], train_loss: 0.03442\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54242\n",
            "epoch: 002 [ 756/2267 ( 33%)], train_loss: 0.03440\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53066\n",
            "epoch: 002 [ 780/2267 ( 34%)], train_loss: 0.03446\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51883\n",
            "epoch: 002 [ 804/2267 ( 35%)], train_loss: 0.03454\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51406\n",
            "epoch: 002 [ 828/2267 ( 37%)], train_loss: 0.03440\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49665\n",
            "epoch: 002 [ 852/2267 ( 38%)], train_loss: 0.03417\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49440\n",
            "epoch: 002 [ 876/2267 ( 39%)], train_loss: 0.03417\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50041\n",
            "epoch: 002 [ 900/2267 ( 40%)], train_loss: 0.03405\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49048\n",
            "epoch: 002 [ 924/2267 ( 41%)], train_loss: 0.03402\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49374\n",
            "epoch: 002 [ 948/2267 ( 42%)], train_loss: 0.03381\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.56647\n",
            "epoch: 002 [ 972/2267 ( 43%)], train_loss: 0.03357\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54748\n",
            "epoch: 002 [ 996/2267 ( 44%)], train_loss: 0.03373\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54280\n",
            "epoch: 002 [1020/2267 ( 45%)], train_loss: 0.03379\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49924\n",
            "epoch: 002 [1044/2267 ( 46%)], train_loss: 0.03369\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.50333\n",
            "epoch: 002 [1068/2267 ( 47%)], train_loss: 0.03346\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51632\n",
            "epoch: 002 [1092/2267 ( 48%)], train_loss: 0.03360\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.59525\n",
            "epoch: 002 [1116/2267 ( 49%)], train_loss: 0.03373\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54235\n",
            "epoch: 002 [1140/2267 ( 50%)], train_loss: 0.03371\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.56472\n",
            "epoch: 002 [1164/2267 ( 51%)], train_loss: 0.03355\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54407\n",
            "epoch: 002 [1188/2267 ( 52%)], train_loss: 0.03354\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54147\n",
            "epoch: 002 [1212/2267 ( 53%)], train_loss: 0.03360\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.51924\n",
            "epoch: 002 [1236/2267 ( 55%)], train_loss: 0.03343\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.48898\n",
            "epoch: 002 [1260/2267 ( 56%)], train_loss: 0.03329\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54406\n",
            "epoch: 002 [1284/2267 ( 57%)], train_loss: 0.03331\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.59060\n",
            "epoch: 002 [1308/2267 ( 58%)], train_loss: 0.03353\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49936\n",
            "epoch: 002 [1332/2267 ( 59%)], train_loss: 0.03347\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.61003\n",
            "epoch: 002 [1356/2267 ( 60%)], train_loss: 0.03359\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.53490\n",
            "epoch: 002 [1380/2267 ( 61%)], train_loss: 0.03367\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.59324\n",
            "epoch: 002 [1404/2267 ( 62%)], train_loss: 0.03359\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.57121\n",
            "epoch: 002 [1428/2267 ( 63%)], train_loss: 0.03361\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54328\n",
            "epoch: 002 [1452/2267 ( 64%)], train_loss: 0.03360\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.54770\n",
            "epoch: 002 [1476/2267 ( 65%)], train_loss: 0.03352\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.52159\n",
            "epoch: 002 [1500/2267 ( 66%)], train_loss: 0.03348\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.55024\n",
            "epoch: 002 [1524/2267 ( 67%)], train_loss: 0.03338\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.49939\n",
            "epoch: 002 [1548/2267 ( 68%)], train_loss: 0.03324\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.66845\n",
            "epoch: 002 [1572/2267 ( 69%)], train_loss: 0.03339\n",
            "----Validation Results Summary----\n",
            "Epoch: [2] train_loss: 0.57066\n",
            "epoch: 002 [1596/2267 ( 70%)], train_loss: 0.03346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p2W4sjDIPh9"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "!cp /content/model0.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    !cp /content/model1.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "!cp /content/model2.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "!cp /content/model2.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "!cp /content/model3.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge\n",
        "!cp /content/model4.bin /content/drive/MyDrive/kaggle/readability/robertaldalarge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Pg9r-h4RUv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}